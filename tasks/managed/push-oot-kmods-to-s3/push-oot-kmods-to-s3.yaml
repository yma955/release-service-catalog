---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: push-oot-kmods-to-s3
spec:
  description: >-
    Task to upload out-of-tree kernel modules to an S3 bucket
  params:
    - name: signedKmodsPath
      type: string
      description: Path where the kernel modules are stored relative to the dataDir
    - name: dataDir
      type: string
      description: The absolute path to the working directory
      default: /var/workdir/release
    - name: s3Endpoint
      type: string
      description: The S3 endpoint URL
    - name: s3Bucket
      type: string
      description: The name of the destination S3 bucket
    - name: s3CredentialsSecret
      type: string
      description: The name of the Kubernetes secret containing S3 credentials
    - name: sourceDataArtifact
      type: string
      description: Location of trusted artifacts to be used to populate data directory
      default: ""
    - name: orasOptions
      description: oras options to pass to Trusted Artifacts calls
      type: string
      default: ""
    - name: trustedArtifactsDebug
      description: Flag to enable debug logging in trusted artifacts. Set to a non-empty string to enable
      type: string
      default: ""
    - name: taskGitUrl
      type: string
      description: The git repository URL for task and StepAction resolution
      default: https://github.com/konflux-ci/release-service-catalog.git
    - name: taskGitRevision
      type: string
      description: The git revision for task and StepAction resolution
      default: main
  volumes:
    - name: workdir
      emptyDir: {}
    - name: s3-credentials-vol
      secret:
        secretName: $(params.s3CredentialsSecret)
  stepTemplate:
    securityContext:
      runAsUser: 1001 
    volumeMounts:
      - mountPath: /var/workdir
        name: workdir
    env:
      - name: "ORAS_OPTIONS"
        value: "$(params.orasOptions)"
      - name: "DEBUG"
        value: "$(params.trustedArtifactsDebug)"
  steps:
    - name: use-trusted-artifact
      computeResources:
        limits:
          memory: 64Mi
        requests:
          memory: 64Mi
          cpu: 30m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/use-trusted-artifact/use-trusted-artifact.yaml
      params:
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(params.sourceDataArtifact)
    - name: upload-to-s3
      image: amazon/aws-cli@sha256:3be2a248274c72a6f76fa0ac042aec84f4ade6ff7f38894df31732da4005294d
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: s3-credentials-vol
          mountPath: /var/secrets/s3
          readOnly: true
      script: |
        #!/usr/bin/env bash
        set -euo pipefail

        AWS_ACCESS_KEY_ID=$(cat /var/secrets/s3/aws_access_key_id)
        export AWS_ACCESS_KEY_ID
        AWS_SECRET_ACCESS_KEY=$(cat /var/secrets/s3/aws_secret_access_key)
        export AWS_SECRET_ACCESS_KEY

        set -x

        SIGNED_KMODS_FULL_PATH="$(params.dataDir)/$(params.signedKmodsPath)"

        # Check if this is a multi-architecture build
        if [ -f "$(params.dataDir)/arch_count.txt" ]; then
            arch_count=$(cat "$(params.dataDir)/arch_count.txt")
            echo "Processing $arch_count architecture(s) for S3 upload"
        else
            echo "No architecture information found, assuming single architecture"
            arch_count=1
        fi

        # Function to upload artifacts for a specific architecture
        upload_arch_artifacts() {
            local arch_name="$1"
            local source_dir="$2"
            local arch_suffix=""

            # Add architecture suffix for multi-arch builds
            if [ "$arch_count" -gt 1 ]; then
                arch_suffix="/${arch_name}"
            fi

            echo "Processing S3 upload for architecture: $arch_name"

            # Read envfile to get version information
            if [ -f "$source_dir/envfile" ]; then
                # shellcheck source=/dev/null
                . "$source_dir/envfile"
            else
                echo "ERROR: envfile not found in $source_dir"
                return 1
            fi

            S3_TARGET_PATH="${DRIVER_VENDOR}/${DRIVER_VERSION}/${KERNEL_VERSION}${arch_suffix}/"
            echo "S3 target path for $arch_name: s3://$(params.s3Bucket)/${S3_TARGET_PATH}"

            # Upload .ko files
            if ls "$source_dir"/*.ko 1> /dev/null 2>&1; then
                echo "Uploading .ko files for $arch_name"
                aws s3 cp \
                  "$source_dir" \
                  "s3://$(params.s3Bucket)/${S3_TARGET_PATH}" \
                  --endpoint-url "$(params.s3Endpoint)" \
                  --recursive \
                  --exclude "*" \
                  --include "*.ko"
            else
                echo "WARNING: No .ko files found for architecture $arch_name"
                return 1
            fi

            # Upload checksum file
            if [ "$arch_count" -gt 1 ]; then
                if [ -f "$source_dir/signed_kmods_checksums_${arch_name}.txt" ]; then
                    echo "Uploading architecture-specific checksums for $arch_name"
                    aws s3 cp \
                      "$source_dir/signed_kmods_checksums_${arch_name}.txt" \
                      "s3://$(params.s3Bucket)/${S3_TARGET_PATH}signed_kmods_checksums_${arch_name}.txt" \
                      --endpoint-url "$(params.s3Endpoint)"
                fi
            else
                if [ -f "$source_dir/signed_kmods_checksums.txt" ]; then
                    echo "Uploading checksums for single architecture"
                    aws s3 cp \
                      "$source_dir/signed_kmods_checksums.txt" \
                      "s3://$(params.s3Bucket)/${S3_TARGET_PATH}signed_kmods_checksums.txt" \
                      --endpoint-url "$(params.s3Endpoint)"
                fi
            fi

            # Upload envfile for reference
            if [ -f "$source_dir/envfile" ]; then
                echo "Uploading envfile for $arch_name"
                aws s3 cp \
                  "$source_dir/envfile" \
                  "s3://$(params.s3Bucket)/${S3_TARGET_PATH}envfile" \
                  --endpoint-url "$(params.s3Endpoint)"
            fi

            return 0
        }

        # Process architectures
        if [ "$arch_count" -gt 1 ]; then
            echo "Multi-architecture build detected, processing each architecture"

            # Upload summary files first
            if [ -f "${SIGNED_KMODS_FULL_PATH}/signing_summary.txt" ]; then
                # Use first architecture's envfile for base path information
                first_arch_dir=$(find "${SIGNED_KMODS_FULL_PATH}" -mindepth 1 -maxdepth 1 -type d | head -1)
                if [ -n "$first_arch_dir" ] && [ -f "$first_arch_dir/envfile" ]; then
                    # shellcheck source=/dev/null
                    . "$first_arch_dir/envfile"
                    summary_s3_path="${DRIVER_VENDOR}/${DRIVER_VERSION}/${KERNEL_VERSION}/multi-arch-summary/"

                    echo "Uploading multi-architecture summary to s3://$(params.s3Bucket)/${summary_s3_path}"
                    aws s3 cp \
                      "${SIGNED_KMODS_FULL_PATH}/signing_summary.txt" \
                      "s3://$(params.s3Bucket)/${summary_s3_path}signing_summary.txt" \
                      --endpoint-url "$(params.s3Endpoint)"

                    if [ -f "${SIGNED_KMODS_FULL_PATH}/extraction_summary.txt" ]; then
                        aws s3 cp \
                          "${SIGNED_KMODS_FULL_PATH}/extraction_summary.txt" \
                          "s3://$(params.s3Bucket)/${summary_s3_path}extraction_summary.txt" \
                          --endpoint-url "$(params.s3Endpoint)"
                    fi
                fi
            fi

            # Process each architecture directory
            for arch_dir in "${SIGNED_KMODS_FULL_PATH}"/*/; do
                if [ -d "$arch_dir" ]; then
                    arch_name=$(basename "$arch_dir")
                    echo "Processing S3 upload for architecture: $arch_name"

                    if upload_arch_artifacts "$arch_name" "$arch_dir"; then
                        echo "Successfully uploaded $arch_name to S3"
                    else
                        echo "ERROR: Failed to upload $arch_name to S3"
                        exit 1
                    fi
                fi
            done

        else
            echo "Single architecture build, using standard upload"

            if upload_arch_artifacts "single" "${SIGNED_KMODS_FULL_PATH}"; then
                echo "Successfully uploaded single architecture to S3"
            else
                echo "ERROR: Failed to upload single architecture to S3"
                exit 1
            fi
        fi

        echo "S3 upload complete for $arch_count architecture(s)."
