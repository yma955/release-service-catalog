---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: sign-index-image
  labels:
    app.kubernetes.io/version: "5.0.1"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: >-
    Task to create an internalrequest to sign a FBC Index Image.
  params:
    - name: dataPath
      description: Path to the JSON string of the merged data to use in the data workspace
      type: string
    - name: releasePlanAdmissionPath
      description: Path to the JSON string of the releasePlanAdmission in the data workspace
      type: string
    - name: referenceImage
      type: string
      description: The image to be signed.
    - name: manifestListDigests
      type: string
      description: The manifest digests for each arch in manifest list
    - name: requester
      type: string
      description: Name of the user that requested the signing, for auditing purposes
    - name: requestTimeout
      type: string
      default: "1800"
      description: InternalRequest timeout
    - name: pipelineRunUid
      type: string
      description: The uid of the current pipelineRun. Used as a label value when creating internal requests
    - name: taskGitUrl
      type: string
      description: |
        The url to the git repo where the release-service-catalog tasks to be used are stored. This is passed to
        the InternalRequest as it is needed by the simple-signing-pipeline
    - name: taskGitRevision
      type: string
      description: |
        The revision in the taskGitUrl repo to be used. This is passed to the InternalRequest as it is needed by the
        simple-signing-pipeline
    - name: fbcResultsPath
      type: string
      description: Path to the JSON file in the data workspace containing fbc results
    - name: concurrentLimit
      type: string
      description: The maximum number of concurrent signing requests
      default: 16
  workspaces:
    - name: data
      description: workspace to read and save files
  steps:
    - name: sign-index-image
      image: quay.io/konflux-ci/release-service-utils:2d6f05c89fc619042a2be19d64ff48de9975397a
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      script: |
        #!/usr/bin/env bash
        set -ex

        RUNNING_JOBS="\j" # Bash parameter for number of jobs currently running
        CONCURRENT_LIMIT=$(params.concurrentLimit)
        REQUEST_COUNT=0

        TASK_LABEL="internal-services.appstudio.openshift.io/group-id"
        TASK_ID=$(context.taskRun.uid)
        PIPELINERUN_LABEL="internal-services.appstudio.openshift.io/pipelinerun-uid"

        DATA_FILE="$(workspaces.data.path)/$(params.dataPath)"
        if [ ! -f "${DATA_FILE}" ] ; then
            echo "No valid data file was provided."
            exit 1
        fi

        RESULTS_FILE="$(workspaces.data.path)/$(params.fbcResultsPath)"
        if [ ! -f "${RESULTS_FILE}" ] ; then
            echo "No valid results file was provided."
            exit 1
        fi

        requestType=$(jq -r '.sign.requestType // "internal-request"' "${DATA_FILE}")
        if [ "${requestType}" == "internal-pipelinerun" ] ; then
          RPA_FILE="$(workspaces.data.path)/$(params.releasePlanAdmissionPath)"
          if [ ! -f "${RPA_FILE}" ] ; then
              echo "No valid rpa file was provided."
              exit 1
          fi
          service_account_name=$(jq -r '.spec.pipeline.serviceAccountName // "release-service-account"' "${RPA_FILE}")
          EXTRA_ARGS=(
          --service-account "${service_account_name}"
          )
        else
          requestType=internal-request
          EXTRA_ARGS=()
        fi
        request=$(jq -r '.sign.request // "simple-signing-pipeline"' "${DATA_FILE}")

        default_pipeline_image="quay.io/redhat-isv/operator-pipelines-images:released"
        pipeline_image=$(jq -r --arg default_pipeline_image "${default_pipeline_image}" \
            '.sign.pipelineImage // .fbc.pipelineImage // $default_pipeline_image' "${DATA_FILE}")
        config_map_name=$(jq -r '.sign.configMapName // .fbc.configMapName // "signing-config-map"' "${DATA_FILE}")

        component_count=$(jq '.components | length' "$RESULTS_FILE")
        for ((i = 0; i < component_count; i++)); do
          reference_image=$(jq -r ".components[$i].target_index" "$RESULTS_FILE")

          # Translate direct quay.io reference to public facing registry reference
          # quay.io/redhat/product----repo -> registry.redhat.io/product/repo
          reference_image=$(translate-delivery-repo "$reference_image" \
            | jq -r '.[] | select(.repo=="redhat.io") | .url')

          digest_count=$(jq ".components[$i].image_digests | length" "$RESULTS_FILE")
          for ((j = 0; j < digest_count; j++)); do
            while (( ${RUNNING_JOBS@P} >= "$CONCURRENT_LIMIT" )); do
              wait -n
            done

            manifest_digest=$(jq -r ".components[$i].image_digests[$j]" "$RESULTS_FILE")

            echo "Creating ${requestType} to sign image:"
            echo "- reference=${reference_image}"
            echo "- manifest_digest=${manifest_digest}"
            echo "- requester=$(params.requester)"

            ${requestType} --pipeline "${request}" \
              -p pipeline_image="${pipeline_image}" \
              -p reference="${reference_image}" \
              -p manifest_digest="${manifest_digest}" \
              -p requester="$(params.requester)" \
              -p config_map_name="${config_map_name}" \
              -p taskGitUrl="$(params.taskGitUrl)" \
              -p taskGitRevision="$(params.taskGitRevision)" \
              -l ${TASK_LABEL}="${TASK_ID}" \
              -l ${PIPELINERUN_LABEL}="$(params.pipelineRunUid)" \
              -t "$(params.requestTimeout)" --pipeline-timeout "0h30m0s" --task-timeout "0h25m0s" \
              "${EXTRA_ARGS[@]}" -s true &

            ((++REQUEST_COUNT))
            echo "Request Count: $REQUEST_COUNT"

          done
        done

        echo "Waiting for remaining processes to finish..."
        while (( ${RUNNING_JOBS@P} > 0 )); do
          wait -n
        done

        echo "done"
