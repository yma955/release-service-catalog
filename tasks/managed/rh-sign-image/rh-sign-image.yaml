---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: rh-sign-image
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: |-
    Task to create internalrequests or pipelineruns to sign snapshot components
  params:
    - name: snapshotPath
      description: Path to the JSON string of the mapped Snapshot spec in the data workspace
      type: string
    - name: dataPath
      description: Path to the JSON string of the merged data to use in the data workspace
      type: string
    - name: releasePlanAdmissionPath
      description: Path to the JSON string of the releasePlanAdmission in the data workspace
      type: string
    - name: requester
      type: string
      description: Name of the user that requested the signing, for auditing purposes
    - name: requestTimeout
      type: string
      default: "1800"
      description: InternalRequest timeout
    - name: concurrentLimit
      type: string
      description: The maximum number of images to be processed at once
      default: 16
    - name: pipelineRunUid
      type: string
      description: The uid of the current pipelineRun. Used as a label value when creating internal requests
    - name: pyxisServer
      type: string
      description: The server type to use. Options are 'production','production-internal,'stage-internal' and 'stage'
      default: production
    - name: pyxisSecret
      type: string
      description: |
        The kubernetes secret to use to authenticate to Pyxis. It needs to contain two keys: key and cert
    - name: batchLimit
      type: string
      description: |
        size of batch attributes to send to internal-request. As internal request arguments are need to be
        strings, size here represent maximal string length of `references` and `manifest_digests` sent to
        internal request
      default: 16384
    - name: signRegistryAccessPath
      type: string
      description: |
        The relative path in the workspace to a text file that contains a list of repositories
        that needs registry.access.redhat.com image references to be signed (i.e.
        requires_terms=true), one repository string per line, e.g. "rhtas/cosign-rhel9"
    - name: ociStorage
      description: The OCI repository where the Trusted Artifacts are stored
      type: string
      default: "empty"
    - name: ociArtifactExpiresAfter
      description: Expiration date for the trusted artifacts created in the
        OCI repository. An empty string means the artifacts do not expire
      type: string
      default: "1d"
    - name: trustedArtifactsDebug
      description: Flag to enable debug logging in trusted artifacts. Set to a non-empty string to enable
      type: string
      default: ""
    - name: orasOptions
      description: oras options to pass to Trusted Artifacts calls
      type: string
      default: ""
    - name: sourceDataArtifact
      type: string
      description: Location of trusted artifacts to be used to populate data directory
      default: ""
    - name: dataDir
      description: The location where data will be stored
      type: string
      default: /var/workdir/release
    - name: taskGitUrl
      type: string
      description: The url to the git repo where the release-service-catalog tasks and stepactions to be used are stored
    - name: taskGitRevision
      type: string
      description: The revision in the taskGitUrl repo to be used
    - name: caTrustConfigMapName
      type: string
      description: The name of the ConfigMap to read CA bundle data from
      default: trusted-ca
    - name: caTrustConfigMapKey
      type: string
      description: The name of the key in the ConfigMap that contains the CA bundle data
      default: ca-bundle.crt
  results:
    - description: Produced trusted data artifact
      name: sourceDataArtifact
      type: string
  volumes:
    - name: workdir
      emptyDir: {}
    - name: pyxis-secret-vol
      secret:
        secretName: $(params.pyxisSecret)
        defaultMode: 0444
    - name: trusted-ca
      configMap:
        name: $(params.caTrustConfigMapName)
        items:
          - key: $(params.caTrustConfigMapKey)
            path: ca-bundle.crt
        optional: true

  stepTemplate:
    volumeMounts:
      - mountPath: /var/workdir
        name: workdir
      - name: trusted-ca
        mountPath: /mnt/trusted-ca
        readOnly: true
    securityContext:
      runAsUser: 1001
    env:
      - name: IMAGE_EXPIRES_AFTER
        value: $(params.ociArtifactExpiresAfter)
      - name: "ORAS_OPTIONS"
        value: "$(params.orasOptions)"
      - name: "DEBUG"
        value: "$(params.trustedArtifactsDebug)"
  steps:
    - name: use-trusted-artifact
      computeResources:
        limits:
          memory: 64Mi
        requests:
          memory: 64Mi
          cpu: 30m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/use-trusted-artifact/use-trusted-artifact.yaml
      params:
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(params.sourceDataArtifact)

    - name: sign-image
      image: quay.io/konflux-ci/release-service-utils@sha256:f10b4ad888634a7633f76ede29003ce1471aec2b76a7d9e01ad282a3011eb78f
      computeResources:
        limits:
          memory: 4Gi
        requests:
          memory: 4Gi
          cpu: "2"
      volumeMounts:
        - name: pyxis-secret-vol
          mountPath: "/etc/secrets"
      env:
        - name: BATCH_LIMIT
          value: $(params.batchLimit)
      script: |
        #!/usr/bin/env bash
        set -e

        pyxisCert="$(cat /etc/secrets/cert)"
        pyxisKey="$(cat /etc/secrets/key)"

        set -x

        RUNNING_JOBS="\j" # Bash parameter for number of jobs currently running
        CONCURRENT_LIMIT=$(params.concurrentLimit)
        REQUEST_COUNT=0

        SNAPSHOT_PATH=$(params.dataDir)/$(params.snapshotPath)
        TASK_LABEL="internal-services.appstudio.openshift.io/group-id"
        TASK_ID=$(context.taskRun.uid)
        PIPELINERUN_LABEL="internal-services.appstudio.openshift.io/pipelinerun-uid"

        DATA_FILE="$(params.dataDir)/$(params.dataPath)"
        if [ ! -f "${DATA_FILE}" ] ; then
            echo "No valid data file was provided."
            exit 1
        fi
        RPA_FILE="$(params.dataDir)/$(params.releasePlanAdmissionPath)"
        if [ ! -f "${RPA_FILE}" ] ; then
            echo "No valid rpa file was provided."
            exit 1
        fi

        SIGN_REGISTRY_ACCESS_FILE=$(params.dataDir)/$(params.signRegistryAccessPath)
        if [ ! -f "${SIGN_REGISTRY_ACCESS_FILE}" ] ; then
            echo "No valid file was provided as signRegistryAccessPath."
            exit 1
        fi

        REQUESTTYPE=$(jq -r '.requestType // "internal-request"' "${DATA_FILE}")
        service_account_name=$(jq -r '.spec.pipeline.serviceAccountName // "release-service-account"' "${RPA_FILE}")
        if [ "${REQUESTTYPE}" == "internal-pipelinerun" ] ; then
          requestType=internal-pipelinerun
          EXTRA_ARGS=(
          --service-account "${service_account_name}"
          )
        else
          requestType=internal-request
          EXTRA_ARGS=()
        fi
        request=$(jq -r '.sign.request // "simple-signing-pipeline"' "${DATA_FILE}")

        default_pipeline_image="quay.io/redhat-isv/operator-pipelines-images:released"

        pipeline_image=$(jq -r --arg default_pipeline_image ${default_pipeline_image} \
            '.sign.pipelineImage // $default_pipeline_image' "${DATA_FILE}")
        config_map_name=$(jq -r '.sign.configMapName // "signing-config-map"' "${DATA_FILE}")
        defaultPushSourceContainer=$(jq -r \
          '.mapping.defaults.pushSourceContainer | if . == null then true else . end' "${DATA_FILE}")

        if [[ "$(params.pyxisServer)" == "production" ]]
        then
          PYXIS_GRAPHQL_URL="https://graphql-pyxis.api.redhat.com/graphql/"
        elif [[ "$(params.pyxisServer)" == "stage" ]]
        then
          PYXIS_GRAPHQL_URL="https://graphql-pyxis.preprod.api.redhat.com/graphql/"
        elif [[ "$(params.pyxisServer)" == "production-internal" ]]
        then
          PYXIS_GRAPHQL_URL="https://graphql.pyxis.engineering.redhat.com/graphql/"
        elif [[ "$(params.pyxisServer)" == "stage-internal" ]]
        then
          PYXIS_GRAPHQL_URL="https://graphql.pyxis.stage.engineering.redhat.com/graphql/"
        else
          echo "Invalid pyxisServer parameter. Only 'production','production-internal,'stage-internal' \
              and 'stage' allowed."
          exit 1
        fi

        set +x
        echo "${pyxisCert:?}" > /tmp/crt
        echo "${pyxisKey:?}" > /tmp/key
        set -x

        export PYXIS_CERT_PATH=/tmp/crt
        export PYXIS_KEY_PATH=/tmp/key

        COMPONENTS_LENGTH=$(jq '.components |length' "${SNAPSHOT_PATH}")
        declare -a to_sign_references=()
        declare -a to_sign_digests=()
        declare -a to_sign_keys=()

        # Arrays to store information for parallel processing
        declare -a find_signatures_files=()
        declare -a component_data=()
        FIND_SIGNATURES_SUCCESS=true
        FIND_SIGNATURES_JOB_COUNT=0

        # First pass: collect all find_signatures calls and start them with concurrency limit
        for (( i = 0; i < COMPONENTS_LENGTH; i++ )); do
            component=$(jq -c --argjson i "$i" '.components[$i]' "${SNAPSHOT_PATH}")
            referenceContainerImage=$(jq -r '.containerImage' <<< "$component")

            # check if multi-arch
            RAW_OUTPUT=$(skopeo inspect --retry-times 3 --no-tags --raw "docker://${referenceContainerImage}")
            # Always sign the top level sha
            manifest_digests="${referenceContainerImage#*@}"
            # For multi arch and index images, also sign all the manifests inside
            MEDIATYPE="$(jq -r '.mediaType' <<< "$RAW_OUTPUT")"
            if [ "$MEDIATYPE" != "application/vnd.oci.image.manifest.v1+json" ] && \
               [ "$MEDIATYPE" != "application/vnd.docker.distribution.manifest.v2+json" ]; then
              nested_digests=$(jq -r '[.manifests[].digest] | join(" ")' <<< "$RAW_OUTPUT")
              manifest_digests="$manifest_digests $nested_digests"
            fi
            echo "MANIFEST DIGESTS: ${manifest_digests}"

            sourceContainerDigest=
            # Push source container if the component has pushSourceContainer: true or if the
            # pushSourceContainer key is missing from the component and the defaults has
            # pushSourceContainer: true or omitted (defaultPushSourceContainer defaults to true)
            if [[ $(jq -r '.pushSourceContainer' <<< "$component") == "true" ]] || \
               [[ $(jq 'has("pushSourceContainer")' <<< "$component") == "false" \
                && ${defaultPushSourceContainer} == "true" ]] ; then
              source_repo=${referenceContainerImage%%@sha256:*}
              source_reference_tag=sha256-${referenceContainerImage#*@sha256:}.src
              # Calculate the source container image based on the provided container image
              sourceContainer="${source_repo}:${source_reference_tag}"

              # oras has very limited support for selecting the right auth entry,
              # so create a custom auth file with just one entry
              AUTH_FILE=$(mktemp)
              select-oci-auth "${sourceContainer}" > "$AUTH_FILE"
              sourceContainerDigest=$(oras resolve --registry-config "$AUTH_FILE" "${sourceContainer}")
            fi

            NUM_REPOS=$(jq -c '.repositories | length' <<< "$component")
            for ((j = 0; j < NUM_REPOS; j++)); do
              repo=$(jq -c --argjson j "$j" '.repositories[$j]' <<< "$component")
              TAGS=$(jq -r '.tags | join(" ")' <<< "$repo")

              rh_registry_repo=$(jq -er '."rh-registry-repo"' <<< "$repo" )
              registry_access_repo=$(jq -er '."registry-access-repo"' <<< "$repo" )
              repository="${rh_registry_repo#*/}"

              # Sign rh-registry-repo references (always) and registry-access-repo references
              # (only if signatures for this registry are required)
              REGISTRY_REFERENCES=("${rh_registry_repo}")
              if grep -q "^${repository}$" "${SIGN_REGISTRY_ACCESS_FILE}"; then
                REGISTRY_REFERENCES+=("${registry_access_repo}")
              fi

              # Store component data for later processing
              component_data+=("${i}|${repository}|${TAGS}|${manifest_digests}|${sourceContainerDigest}|${rh_registry_repo}|${registry_access_repo}")

              # Start find_signatures jobs in parallel for manifest digests
              for manifest_digest in $manifest_digests; do
                while (( ${RUNNING_JOBS@P} >= "$CONCURRENT_LIMIT" )); do
                  wait -n || FIND_SIGNATURES_SUCCESS=false
                done

                echo "Starting find_signatures job for manifest digest: ${manifest_digest}"
                digest_filename="${manifest_digest//:/_}"
                ((++FIND_SIGNATURES_JOB_COUNT))
                find_signatures_files+=("${digest_filename}")
                find_signatures --pyxis-graphql-api "${PYXIS_GRAPHQL_URL}" \
                --manifest_digest "${manifest_digest}" \
                --repository "${repository}" \
                --output_file "/tmp/${manifest_digest}" \
                > "/tmp/find_sig_${digest_filename}.out" \
                2> "/tmp/find_sig_${digest_filename}.err" &
                find_signatures_jobs+=($!)
              done

              # Start find_signatures job for source container digest if it exists
              if [ "${sourceContainerDigest}" != "" ] ; then
                while (( ${RUNNING_JOBS@P} >= "$CONCURRENT_LIMIT" )); do
                  wait -n || FIND_SIGNATURES_SUCCESS=false
                done

                echo "Starting find_signatures job for source container digest: ${sourceContainerDigest}"
                digest_filename="${manifest_digest//:/_}"
                ((++FIND_SIGNATURES_JOB_COUNT))
                find_signatures_files+=("${digest_filename}")
                find_signatures --pyxis-graphql-api "${PYXIS_GRAPHQL_URL}" \
                --manifest_digest "${sourceContainerDigest}" \
                --repository "${repository}" \
                --output_file "/tmp/${sourceContainerDigest}" \
                > "/tmp/find_sig_${digest_filename}.out" \
                2> "/tmp/find_sig_${digest_filename}.err" &
                find_signatures_jobs+=($!)
              fi

            done
        done

        # Wait for all find_signatures jobs to complete
        echo "Waiting for ${FIND_SIGNATURES_JOB_COUNT} find_signatures jobs to complete..."
        while (( ${RUNNING_JOBS@P} > 0 )); do
          wait -n || FIND_SIGNATURES_SUCCESS=false
        done
        echo "All find_signatures jobs completed"

        # Print outputs and errors for each find_signatures job
        for digest_filename in "${find_signatures_files[@]}"; do
            if [ -f "/tmp/find_sig_${digest_filename}.out" ]; then
                echo "=== find_signatures Output (${digest_filename}) ==="
                cat "/tmp/find_sig_${digest_filename}.out"
                echo
            fi
            if [ -f "/tmp/find_sig_${digest_filename}.err" ] && \
               [ -s "/tmp/find_sig_${digest_filename}.err" ]; then
                echo "=== find_signatures Errors (${digest_filename}) ==="
                cat "/tmp/find_sig_${digest_filename}.err"
                echo
            fi
        done
        if [ "$FIND_SIGNATURES_SUCCESS" != true ]; then
            echo "One or more find_signatures jobs failed. Please check the logs above for details."
            exit 1
        fi

        # Gather all signing keys
        jqquery='.data|if has ("SIG_KEY_NAMES")
        then (.SIG_KEY_NAMES|split(",")|.[]|gsub("^\\s+|\\s+$";"")) else .SIG_KEY_NAME end'

        config_map_name=$(jq -r '.sign.configMapName // "signing-config-map"' "${DATA_FILE}")
        configMapJson=$(kubectl get "cm/${config_map_name:?}" -ojson)
        SIG_KEY_NAMES=$(jq -er "$jqquery" <<< "${configMapJson}")

        # Second pass: process the results now that all find_signatures calls are complete
        for component_info in "${component_data[@]}"; do
            echo "Processing component_info: ${component_info}"

            IFS='|' read -r i repository TAGS manifest_digests sourceContainerDigest \
              rh_registry_repo registry_access_repo <<< "$component_info"

            echo "repository: ${repository}"
            echo "TAGS: ${TAGS}"
            echo "manifest_digests: ${manifest_digests}"
            echo "sourceContainerDigest: ${sourceContainerDigest}"
            echo "rh_registry_repo: ${rh_registry_repo}"
            echo "registry_access_repo: ${registry_access_repo}"

            # Sign rh-registry-repo references (always) and registry-access-repo references
            # (only if signatures for this registry are required)
            REGISTRY_REFERENCES=("${rh_registry_repo}")
            if grep -q "^${repository}$" "${SIGN_REGISTRY_ACCESS_FILE}"; then
              REGISTRY_REFERENCES+=("${registry_access_repo}")
            fi

            for sig_key in ${SIG_KEY_NAMES}; do
              for manifest_digest in $manifest_digests; do
                # Iterate over both rh-registry-repo and registry-access-repo
                for registry_reference in "${REGISTRY_REFERENCES[@]}"; do

                  for tag in ${TAGS}; do

                    if ! grep -q "^${registry_reference}:${tag} ${sig_key}$" "/tmp/${manifest_digest}" ; then
                      to_sign_references+=("${registry_reference}:${tag}")
                      to_sign_digests+=("${manifest_digest}")
                      to_sign_keys+=("${sig_key}")
                    else
                      echo "Signature already exists for:"
                      echo "- reference=${registry_reference}:${tag}"
                      echo "- manifest_digest=${manifest_digest}"
                    fi

                  done
                done
              done
            done

            for sig_key in ${SIG_KEY_NAMES}; do
              if [ "${sourceContainerDigest}" != "" ] ; then

                  for registry_reference in "${REGISTRY_REFERENCES[@]}"; do

                    for tag in ${TAGS}; do
                      sourceTag=${tag}-source
                      expected="^${registry_reference}:${sourceTag} ${sig_key}$"
                      if ! grep -q "$expected" "/tmp/${sourceContainerDigest}" ; then
                        to_sign_references+=("${registry_reference}:${sourceTag}")
                        to_sign_digests+=("${sourceContainerDigest}")
                        to_sign_keys+=("${sig_key}")
                      else
                        echo "Signature already exists for:"
                        echo "- reference=${registry_reference}:${sourceTag}"
                        echo "- manifest_digest=${sourceContainerDigest}"
                      fi
                    done
                  done
              fi
            done
        done

        declare -A ref_dig_to_keys_map=()
        declare -A keys_to_ref_dig_map=()
        #
        # For each reference-digest pair, build a map of signing keys which need to be signed
        for i in "${!to_sign_references[@]}"; do
          ref="${to_sign_references[$i]}"
          dig="${to_sign_digests[$i]}"
          key="${to_sign_keys[$i]}"
          pair="${ref}|${dig}"
          # if key is not already in the list for this pair, add it
          if [[ ",${ref_dig_to_keys_map[$pair]-}," != *",$key,"* ]]; then
            if [[ -n "${ref_dig_to_keys_map[$pair]-}" ]]; then
              ref_dig_to_keys_map[$pair]+=",$key"
            else
              ref_dig_to_keys_map[$pair]="${key}"
            fi
          fi
        done

        # Create mapping of keysets to reference-digest pairs
        for pair in "${!ref_dig_to_keys_map[@]}"; do
          # sort keys
          IFS=',' read -r -a karr <<< "${ref_dig_to_keys_map[$pair]}"
          mapfile -t sorted_keys < <(IFS=' ' printf '%s\n' "${karr[@]}" | sort)
          keyset="${sorted_keys[*]}"
          keyset="${keyset//$' '/,}"  # join with commas

          if [[ -n "${keys_to_ref_dig_map[$keyset]-}" ]]; then
            keys_to_ref_dig_map["$keyset"]+="#${pair}"
          else
            keys_to_ref_dig_map["$keyset"]="${pair}"
          fi
        done

        for keyset in "${!keys_to_ref_dig_map[@]}"; do

          references_batch=""
          digests_batch=""

          IFS='#' read -r -a pairs <<< "${keys_to_ref_dig_map[$keyset]}"
          for pair in "${pairs[@]}"; do
            IFS="|" read -r reference digest <<< "$pair"

            keyset_spaces="${keyset//,/ }"  # replace , with spaces

            new_references_batch="${references_batch}${reference} "
            new_digests_batch="${digests_batch}${digest} "

            while (( ${RUNNING_JOBS@P} >= "$CONCURRENT_LIMIT" )); do
              wait -n
            done

            if [[ ${#new_references_batch} -gt $BATCH_LIMIT || ${#new_digests_batch} -gt $BATCH_LIMIT ]]; then
              echo "游릭 Creating ${requestType} to sign images: ${references_batch}"
              echo "游릭 - digests: ${digests_batch[*]}"
              echo "游릭 - keys: ${keyset_spaces}"

              ${requestType} \
                --pipeline "${request}" \
                -p pipeline_image="${pipeline_image}" \
                -p references="${references_batch}" \
                -p signing_key_names="${keyset_spaces}" \
                -p manifest_digests="${digests_batch}" \
                -p config_map_name="${config_map_name}" \
                -p requester="$(params.requester)" \
                -p taskGitUrl="$(params.taskGitUrl)" \
                -p taskGitRevision="$(params.taskGitRevision)" \
                -l ${TASK_LABEL}="${TASK_ID}" \
                -l ${PIPELINERUN_LABEL}="$(params.pipelineRunUid)" \
                -t "$(params.requestTimeout)" --pipeline-timeout "0h30m0s" --task-timeout "0h25m0s" \
                "${EXTRA_ARGS[@]}" -s true &
                ((++REQUEST_COUNT))
                echo "Request Count: $REQUEST_COUNT"
                references_batch="${reference} "
                digests_batch="${digest} "
            else
              # if batches are still small enough, add the values to the batches
              references_batch="${new_references_batch}"
              digests_batch="${new_digests_batch}"
            fi

          done
          if [[ ${#references_batch} -gt 0 ]]; then
            while (( ${RUNNING_JOBS@P} >= "$CONCURRENT_LIMIT" )); do
              wait -n
            done

            echo "游릭 Creating ${requestType} to sign images: ${references_batch}"
            echo "游릭 - digests: ${digests_batch[*]}"
            echo "游릭 - keys: ${keyset_spaces}"

            ${requestType} \
              --pipeline "${request}" \
              -p pipeline_image="${pipeline_image}" \
              -p references="${references_batch[*]}" \
              -p signing_key_names="${keyset_spaces}" \
              -p manifest_digests="${digests_batch[*]}" \
              -p config_map_name="${config_map_name}" \
              -p requester="$(params.requester)" \
              -p taskGitUrl="$(params.taskGitUrl)" \
              -p taskGitRevision="$(params.taskGitRevision)" \
              -l ${TASK_LABEL}="${TASK_ID}" \
              -l ${PIPELINERUN_LABEL}="$(params.pipelineRunUid)" \
              -t "$(params.requestTimeout)" --pipeline-timeout "0h30m0s" --task-timeout "0h25m0s" \
              "${EXTRA_ARGS[@]}" -s true &
              ((++REQUEST_COUNT))
              echo "Request Count: $REQUEST_COUNT"

            # next batches consist of values which didn't fit in the previous batches
            references_batch="${to_sign_references[$i]} "
            digests_batch="${to_sign_digests[$i]} "
          else
            # if batches are still small enough, add the values to the batches
            references_batch="${new_references_batch}"
            digests_batch="${new_digests_batch}"

          ${requestType} \
            --pipeline "${request}" \
            -p pipeline_image="${pipeline_image}" \
            -p references="${references_batch[*]}" \
            -p signing_key_names="${keyset_spaces}" \
            -p manifest_digests="${digests_batch[*]}" \
            -p config_map_name="${config_map_name}" \
            -p requester="$(params.requester)" \
            -p taskGitUrl="$(params.taskGitUrl)" \
            -p taskGitRevision="$(params.taskGitRevision)" \
            -l ${TASK_LABEL}="${TASK_ID}" \
            -l ${PIPELINERUN_LABEL}="$(params.pipelineRunUid)" \
            -t "$(params.requestTimeout)" --pipeline-timeout "0h30m0s" --task-timeout "0h25m0s" \
            "${EXTRA_ARGS[@]}" -s true &
          fi
        done

        echo "Waiting for remaining processes to finish..."
        while (( ${RUNNING_JOBS@P} > 0 )); do
          wait -n
        done
        echo "done"

    - name: create-trusted-artifact
      computeResources:
        limits:
          memory: 128Mi
        requests:
          memory: 128Mi
          cpu: 250m
      ref:
        resolver: "git"
        params:
          - name: url
            value: "$(params.taskGitUrl)"
          - name: revision
            value: "$(params.taskGitRevision)"
          - name: pathInRepo
            value: stepactions/create-trusted-artifact/create-trusted-artifact.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(results.sourceDataArtifact.path)
