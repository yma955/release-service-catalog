---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: add-fbc-contribution
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: |-
    Task to create internalrequests to add fbc contributions to index images. It can batch
    multiple fragments into a single IIB request and can also split requests according
    to their OCP versions.

    This task batches FBC fragments to submit them to IIB in sets of params.maxBatchSize.
    The Snapshot has been previously augmented by prepare-fbc-snapshot to include OCP and
    target index metadata for each component.

    In this task, we split fragments up by their OCP versions and then process each of these
    in parallel. Multiple OCP version groups are processed simultaneously, as IIB is capable
    of handling updates to index images for different OCP versions in parallel (but only one
    request at a time for a given version). For each OCP version, we chain together batches so that
    the final targetIndex produced will have all fragments added. This means that the index_image
    from one internal request will be set as the fromIndex for the next request within that OCP
    version. This parallel approach significantly reduces FBC release duration, as the total time
    is only as long as the slowest IIB run rather than the sum of all IIB run durations.

    Since we have seen flakiness in IIB requests in the past, we retry and failed batches
    and internal requests can attach onto currently in progress IIB requests. We retry batches
    at the end to allow for timed out requests to finish so that we can just get the final
    result. This will slightly compress the time in which batches are entered into the IIB
    queue to reduce the effect of a full queue on a single release.
  params:
    - name: snapshotPath
      description: Path to the JSON string of the mapped Snapshot spec in the data workspace
      type: string
    - name: dataPath
      description: Path to the JSON string of the merged data to use in the data workspace
      type: string
    - name: pipelineRunUid
      type: string
      description: The uid of the current pipelineRun. Used as a label value when creating internal requests
    - name: resultsDirPath
      type: string
      description: Path to the results directory in the data workspace
    - name: ociStorage
      description: The OCI repository where the Trusted Artifacts are stored
      type: string
      default: "empty"
    - name: ociArtifactExpiresAfter
      description: Expiration date for the trusted artifacts created in the
        OCI repository. An empty string means the artifacts do not expire
      type: string
      default: "1d"
    - name: trustedArtifactsDebug
      description: Flag to enable debug logging in trusted artifacts. Set to a non-empty string to enable
      type: string
      default: ""
    - name: orasOptions
      description: oras options to pass to Trusted Artifacts calls
      type: string
      default: ""
    - name: sourceDataArtifact
      type: string
      description: Location of trusted artifacts to be used to populate data directory
      default: ""
    - name: dataDir
      description: The location where data will be stored
      type: string
      default: /var/workdir/release
    - name: taskGitUrl
      type: string
      description: The url to the git repo where the release-service-catalog tasks and stepactions to be used are stored
    - name: taskGitRevision
      type: string
      description: The revision in the taskGitUrl repo to be used
    - name: maxBatchSize
      type: string
      description: Maximum number of FBC fragments to process in a single batch
      default: "5"
    - name: mustPublishIndexImage
      type: string
      description: Whether the index image should be published (from prepare-fbc-parameters)
    - name: mustOverwriteFromIndexImage
      type: string
      description: Whether to overwrite the from index image (from prepare-fbc-parameters)
    - name: iibServiceAccountSecret
      type: string
      description: IIB service account secret name (from prepare-fbc-parameters)
    - name: maxRetries
      description: Maximum number of retry attempts for failed internal requests
      type: string
      default: "3"
    - name: batchRetryDelaySeconds
      description: Delay between batch retry attempts in seconds
      type: string
      default: "60"
    - name: caTrustConfigMapName
      type: string
      description: The name of the ConfigMap to read CA bundle data from
      default: trusted-ca
    - name: caTrustConfigMapKey
      type: string
      description: The name of the key in the ConfigMap that contains the CA bundle data
      default: ca-bundle.crt
    - name: overrideMemoryLimitMi
      type: string
      description: Override memory limit for testing adaptive calculation (empty = auto-detect from cgroups)
      default: ""
  results:
    - name: buildTimestamp
      description: Build timestamp used in the tag
    - name: requestResultsFile
      description: Internal Request results file
    - name: internalRequestResultsFile
      description: Additional Internal Request results file
    - name: sourceDataArtifact
      type: string
      description: Produced trusted data artifact
  volumes:
    - name: workdir
      emptyDir: {}
    - name: trusted-ca
      configMap:
        name: $(params.caTrustConfigMapName)
        items:
          - key: $(params.caTrustConfigMapKey)
            path: ca-bundle.crt
        optional: true
  stepTemplate:
    volumeMounts:
      - mountPath: /var/workdir
        name: workdir
      - name: trusted-ca
        mountPath: /mnt/trusted-ca
        readOnly: true
    env:
      - name: IMAGE_EXPIRES_AFTER
        value: $(params.ociArtifactExpiresAfter)
      - name: "ORAS_OPTIONS"
        value: "$(params.orasOptions)"
      - name: "DEBUG"
        value: "$(params.trustedArtifactsDebug)"
    securityContext:
      runAsUser: 1001
  steps:
    - name: use-trusted-artifact
      computeResources:
        limits:
          memory: 64Mi
        requests:
          memory: 64Mi
          cpu: 30m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/use-trusted-artifact/use-trusted-artifact.yaml
      params:
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(params.sourceDataArtifact)
        - name: orasOptions
          value: $(params.orasOptions)
    - name: add-contribution
      image: quay.io/konflux-ci/release-service-utils@sha256:f10b4ad888634a7633f76ede29003ce1471aec2b76a7d9e01ad282a3011eb78f
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi  # was exiting with code 137 when set to 256Mi
          cpu: 200m
      script: |
        #!/usr/bin/env bash
        #
        set -eo pipefail

        SNAPSHOT_PATH="$(params.dataDir)/$(params.snapshotPath)"
        DATA_FILE="$(params.dataDir)/$(params.dataPath)"
        if [ ! -f "${DATA_FILE}" ] ; then
            echo "No valid data file was provided."
            exit 1
        fi

        # The snapshot should be updated by prepare-fbc-snapshot
        SNAPSHOT_PATH="$(params.dataDir)/$(params.snapshotPath)"
        if [ ! -f "$SNAPSHOT_PATH" ]; then
            echo "ERROR: Snapshot not found at $SNAPSHOT_PATH"
            exit 1
        fi

        # adding a new result as modifying the current one used breaks e2e for single component.
        # to be handled in RELEASE-1640.
        RESULTS_FILE="$(params.resultsDirPath)/internal-requests-results.json"
        echo -n "$RESULTS_FILE" > "$(results.internalRequestResultsFile.path)"
        RESULTS_FILE="$(params.dataDir)/$(params.resultsDirPath)/internal-requests-results.json"

        echo -n "$(params.dataDir)/$(params.pipelineRunUid)/ir-$(context.taskRun.uid)-result.json" \
          > "$(results.requestResultsFile.path)"

        default_build_timeout_seconds="3600"
        default_request_timeout_seconds="3600"

        build_timeout_seconds=$(jq -r --arg build_timeout_seconds "${default_build_timeout_seconds}" \
            '.fbc.buildTimeoutSeconds // $build_timeout_seconds' "${DATA_FILE}")
        request_timeout_seconds=$(jq -r --arg request_timeout_seconds "${default_request_timeout_seconds}" \
            '.fbc.requestTimeoutSeconds // $request_timeout_seconds' "${DATA_FILE}")
        internal_request_service_account=$(jq -r '.fbc.internalRequestServiceAccount // "release-service-account"' \
            "${DATA_FILE}")
        publishing_credentials=$(jq -r '.fbc.publishingCredentials // "catalog-publishing-secret"' "$DATA_FILE")

        # Use pre-determined values from prepare-fbc-parameters
        iib_service_account_secret="$(params.iibServiceAccountSecret)"
        mustPublishIndexImage="$(params.mustPublishIndexImage)"
        mustOverwriteFromIndexImage="$(params.mustOverwriteFromIndexImage)"

        timestamp_format=$(jq -r '.fbc.timestampFormat // "%s"' "${DATA_FILE}")
        timestamp=$(date "+${timestamp_format}")

        # Extract OCP versions from snapshot directly into array
        readarray -t ocp_versions_array < <(jq -r '.components[].ocpVersion' "$SNAPSHOT_PATH" | sort -u)
        echo "INFO: Found OCP versions: ${ocp_versions_array[*]}"

        echo "INFO: Using pre-determined values from prepare-fbc-parameters:"
        echo "  - mustPublishIndexImage: ${mustPublishIndexImage}"
        echo "  - mustOverwriteFromIndexImage: ${mustOverwriteFromIndexImage}"
        echo "  - iibServiceAccountSecret: ${iib_service_account_secret}"

        # Initialize results file for multi-OCP processing
        echo -n "$timestamp" > "$(results.buildTimestamp.path)"
        jq -n '{"components": []}' | tee "$RESULTS_FILE"

        # Snapshot validation for multi-OCP processing
        if ! jq -e '.components | type == "array" and length > 0' "$SNAPSHOT_PATH" > /dev/null; then
            echo "ERROR: Snapshot missing required 'components' array"
            exit 1
        fi

        # Validate snapshot for processing
        echo "INFO: Validating snapshot for processing..."
        total_components=$(jq '.components | length' "$SNAPSHOT_PATH")

        if [ "${total_components}" -eq 0 ]; then
            echo "ERROR: No components found in snapshot"
            exit 1
        fi

        echo "INFO: Processing ${total_components} components"

        # Setup consistent labeling for FBC internal requests
        TASK_LABEL="internal-services.appstudio.openshift.io/group-id"
        TASK_ID=$(context.taskRun.uid)
        PIPELINERUN_LABEL="internal-services.appstudio.openshift.io/pipelinerun-uid"

        # Create batches with size limits
        LENGTH=$(jq -r '.components | length' "${SNAPSHOT_PATH}")
        MAX_BATCH_SIZE="$(params.maxBatchSize)"
        echo "Processing $LENGTH components with maximum batch size of $MAX_BATCH_SIZE..."

        # Read global buildTags and addArches from data file
        build_tags=$(jq '.fbc.buildTags // []' "${DATA_FILE}")
        add_arches=$(jq '.fbc.addArches // []' "${DATA_FILE}")

        # Processing will use group-specific target indexes
        # Each OCP version group will have its own target index resolved by prepare-fbc-parameters
        # No single "global" target index exists - each component gets its OCP-specific target index

        # Calculate number of batches needed
        NUM_BATCHES=$(( (LENGTH + MAX_BATCH_SIZE - 1) / MAX_BATCH_SIZE ))
        echo "Creating $NUM_BATCHES batch(es) for $LENGTH components"

        echo "INFO: Processing snapshot components"
        # Create groups directory
        groups_dir="$(params.dataDir)/ocp-groups"
        mkdir -p "$groups_dir"

        # Calculate timeout for batches
        finally_task_timeout=300
        pipeline_timeout=$(date -u "+%Hh%Mm%Ss" -d @$(( request_timeout_seconds + finally_task_timeout )))
        task_timeout=$(date -u "+%Hh%Mm%Ss" -d @$(( request_timeout_seconds )))

        # Group components by OCP version for isolated processing
        group_components_by_ocp_version() {
            local snapshot_file="$1"
            shift  # Remove first argument, remaining are ocp versions
            local ocp_versions=("$@")

            # Group components by OCP version
            for ocp_version in "${ocp_versions[@]}"; do
                local group_file="${groups_dir}/${ocp_version}.json"
                jq --arg ocp_version "$ocp_version" \
                    '.components | map(select(.ocpVersion == $ocp_version))' \
                    "$snapshot_file" > "$group_file"

                local group_count
                group_count=$(jq 'length' "$group_file")
                echo "INFO: OCP version $ocp_version has $group_count components" >&2
            done
        }

        # Group components by OCP versions
        group_components_by_ocp_version "$SNAPSHOT_PATH" "${ocp_versions_array[@]}"

        # Calculate optimal parallelism based on available memory
        # TODO: This cgroups detection logic will be replaced with a uniform solution for all tasks
        calculate_max_parallel_workers() {
            local memory_limit_bytes=0
            local memory_limit_mib=0
            
            # Check for test override first
            if [ -n "$(params.overrideMemoryLimitMi)" ]; then
                memory_limit_mib=$(params.overrideMemoryLimitMi)
                echo "INFO: Using test override memory limit: ${memory_limit_mib}Mi" >&2
            else
                # Try cgroups v2 first (newer systems)
                if [ -f /sys/fs/cgroup/memory.max ]; then
                    local mem_max
                    mem_max=$(cat /sys/fs/cgroup/memory.max 2>/dev/null || echo "max")
                    if [ "$mem_max" != "max" ]; then
                        memory_limit_bytes=$mem_max
                        echo "INFO: Detected cgroups v2 memory limit: $memory_limit_bytes bytes" >&2
                    else
                        # cgroups v2 exists but reports no limit - return conservative default
                        echo "INFO: cgroups v2 reports no memory limit (max), using conservative default" >&2
                        echo "3"
                        return
                    fi
                fi
                
                # Fallback to cgroups v1 (only if cgroups v2 not present)
                if [ "$memory_limit_bytes" -eq 0 ] && [ -f /sys/fs/cgroup/memory/memory.limit_in_bytes ]; then
                    memory_limit_bytes=$(cat /sys/fs/cgroup/memory/memory.limit_in_bytes 2>/dev/null || echo "0")
                    echo "INFO: Detected cgroups v1 memory limit: $memory_limit_bytes bytes" >&2
                fi
            
                # If no limit detected or limit is absurdly high (no actual limit), use conservative default
                if [ "$memory_limit_bytes" -eq 0 ] || [ "$memory_limit_bytes" -gt 107374182400 ]; then
                    echo "WARN: No memory limit detected or limit too high, using conservative default" >&2
                    echo "3"
                    return
                fi
                
                # Convert to MiB
                memory_limit_mib=$((memory_limit_bytes / 1024 / 1024))
                echo "INFO: Memory limit: ${memory_limit_mib}Mi" >&2
            fi
            
            # Estimated memory usage per worker (based on observed usage):
            # - JSON processing with jq: ~30-40Mi
            # - kubectl operations and output buffers: ~30-40Mi
            # - Bash subprocess overhead: ~10-20Mi
            # - Safety margin: 20%
            # Total: ~100Mi per worker conservatively
            local memory_per_worker_mib=100
            
            # Reserve base memory for main script operations
            # - Initial snapshot loading and parsing: ~50Mi
            # - Results aggregation: ~30Mi
            # - System overhead: ~50Mi
            local base_memory_mib=130
            
            local available_for_workers=$((memory_limit_mib - base_memory_mib))
            
            if [ "$available_for_workers" -lt "$memory_per_worker_mib" ]; then
                echo "WARN: Very low memory available (${available_for_workers}Mi), using single worker" >&2
                echo "1"
                return
            fi
            
            local optimal_workers=$((available_for_workers / memory_per_worker_mib))
            
            local max_cap=8
            if [ "$optimal_workers" -gt "$max_cap" ]; then
                echo "INFO: Calculated $optimal_workers workers, capping at $max_cap to avoid IIB overload" >&2
                optimal_workers=$max_cap
            fi
            
            if [ "$optimal_workers" -lt 1 ]; then
                optimal_workers=1
            fi
            
            echo "INFO: Adaptive parallelism: ${memory_limit_mib}Mi limit, ${memory_per_worker_mib}Mi per worker" >&2
            echo "INFO: Calculated optimal parallel workers: $optimal_workers" >&2
            
            echo "$optimal_workers"
        }

        # Process all OCP groups in parallel with bounded parallelism
        process_all_ocp_groups() {
            echo "INFO: Starting parallel group processing with adaptive worker limits"

            local parallel_dir
            parallel_dir="$(params.dataDir)/parallel-tracking"
            mkdir -p "$parallel_dir"
            
            export parallel_dir

            # Calculate optimal parallelism based on available memory
            local max_parallel_workers
            max_parallel_workers=$(calculate_max_parallel_workers)
            
            local total_groups=${#ocp_versions_array[@]}
            
            echo "INFO: Processing $total_groups OCP groups with maximum $max_parallel_workers parallel workers"

            # Arrays to track state
            local pids=()
            local pid_to_ocp=()
            local failed_groups=()
            local completed_count=0
            local launched_count=0
            
            # Launch workers with bounded parallelism
            for ocp_version in "${ocp_versions_array[@]}"; do
                while [ ${#pids[@]} -ge "$max_parallel_workers" ]; do
                    echo "INFO: At parallel limit ($max_parallel_workers active workers), waiting for completion..."
                    
                    # Wait for any worker to complete
                    local completed_pid=""
                    for pid in "${pids[@]}"; do
                        if ! ps -p "$pid" > /dev/null 2>&1; then
                            completed_pid=$pid
                            break
                        fi
                    done
                    
                    if [ -z "$completed_pid" ]; then
                        sleep 1
                        continue
                    fi
                    
                    if wait "$completed_pid" 2>/dev/null; then
                        echo "INFO: Worker (PID: $completed_pid) completed successfully"
                        completed_count=$((completed_count + 1))
                    else
                        local exit_code=$?
                        echo "ERROR: Worker (PID: $completed_pid) failed with exit code $exit_code"
                        failed_groups+=("$completed_pid")
                    fi
                    
                    local new_pids=()
                    for pid in "${pids[@]}"; do
                        if [ "$pid" != "$completed_pid" ]; then
                            new_pids+=("$pid")
                        fi
                    done
                    pids=("${new_pids[@]}")
                done
                
                local group_file="${groups_dir}/${ocp_version}.json"
                launched_count=$((launched_count + 1))
                echo "INFO: Launching worker $launched_count/$total_groups for OCP group: $ocp_version"

                local group_components
                group_components=$(cat "$group_file")

                (
                    set -e
                    
                    echo "INFO: [Parallel Worker $ocp_version] Starting processing"
                    
                    process_ocp_group "$ocp_version" "$group_components"
                    
                    echo "SUCCESS" > "${parallel_dir}/${ocp_version}.status"
                    echo "INFO: [Parallel Worker $ocp_version] Completed successfully"
                ) &
                
                local pid=$!
                pids+=("$pid")
                pid_to_ocp+=("$pid:$ocp_version")
                echo "INFO: Launched worker for OCP $ocp_version (PID: $pid)" \
                     "[Active workers: ${#pids[@]}/$max_parallel_workers]"
            done

            echo "INFO: All $total_groups workers launched, waiting for final ${#pids[@]} to complete..."

            # Wait for remaining background processes and track failures
            for pid in "${pids[@]}"; do
                local ocp_version="unknown"
                for mapping in "${pid_to_ocp[@]}"; do
                    if [[ "$mapping" == "$pid:"* ]]; then
                        ocp_version="${mapping#*:}"
                        break
                    fi
                done
                
                if wait "$pid"; then
                    echo "INFO: Worker for OCP $ocp_version (PID: $pid) completed successfully"
                    completed_count=$((completed_count + 1))
                else
                    local exit_code=$?
                    echo "ERROR: Worker for OCP $ocp_version (PID: $pid) failed with exit code $exit_code"
                    failed_groups+=("$ocp_version")
                fi
            done

            # Check if any groups failed
            # ToDo: verify if we can proceed with partial release
            if [ ${#failed_groups[@]} -gt 0 ]; then
                echo "ERROR: ${#failed_groups[@]} OCP group(s) failed processing" \
                     "(adaptive limit: $max_parallel_workers):"
                for failed_group in "${failed_groups[@]}"; do
                    echo "  - OCP version: $failed_group"
                done
                echo "Cannot proceed with partial release - all OCP groups must succeed"
                exit 1
            fi

            echo "INFO: All parallel processing completed successfully for $total_groups OCP groups"
            echo "INFO: Adaptive parallelism used $max_parallel_workers concurrent workers"

            echo "INFO: Merging results from all parallel workers"
            for ocp_version in "${ocp_versions_array[@]}"; do
                local worker_file="${parallel_dir}/${ocp_version}-results.json"
                if [ -f "$worker_file" ]; then
                    local worker_components
                    worker_components=$(jq -c '.components[]' "$worker_file")
                    if [ -n "$worker_components" ]; then
                        while IFS= read -r component; do
                            export component
                            yq -i '.components += [ env(component) ]' "$RESULTS_FILE"
                        done <<< "$worker_components"
                        echo "INFO: Merged results from OCP $ocp_version worker"
                    else
                        echo "WARNING: Worker file for OCP $ocp_version is empty"
                    fi
                else
                    echo "ERROR: Worker results file missing for OCP $ocp_version"
                    exit 1
                fi
            done
            echo "INFO: Results merge completed"
        }

        # Process OCP group
        process_ocp_group() {
            local group_ocp_version="$1"
            local group_components="$2"

            echo "INFO: Processing OCP group $group_ocp_version"

            # Create per-worker results file to avoid concurrent write conflicts
            local worker_results_file="${parallel_dir}/${group_ocp_version}-results.json"
            jq -n '{components: []}' > "$worker_results_file"
            echo "INFO: Worker results will be written to $worker_results_file"

            # Get group-specific parameters from first component (all should have same values within group)
            local first_component
            first_component=$(jq -r '.[0]' <<< "$group_components")
            local group_from_index
            group_from_index=$(jq -r '.updatedFromIndex // empty' <<< "$first_component")
            local group_target_index
            group_target_index=$(jq -r '.targetIndex // empty' <<< "$first_component")

            # Group parameters are already validated globally, but verify tag format
            echo "INFO: Group parameters - fromIndex: $group_from_index, targetIndex: $group_target_index"

            # Extract and validate tag from group target index for PLR identification
            # For staged releases, targetIndex is empty so no tag extraction is needed
            if [ -n "$group_target_index" ]; then
                group_target_tag=$(printf '%s' "${group_target_index}" | rev | cut -d: -f1 | rev)
                if [[ "$group_target_tag" = "${group_target_index}" ]]; then
                    echo "ERROR: Target index for OCP group $group_ocp_version has no tag: $group_target_index"
                    exit 1
                fi
                echo "INFO: Using tag '$group_target_tag' for PLR identification in OCP group $group_ocp_version"

                # Add group-specific PLR identifier to build tags
                group_build_tags=$(echo "${build_tags}" | jq --arg tag "$group_target_tag" '. + [$tag]')
            else
                echo "INFO: No target index for OCP group $group_ocp_version (staged release), skipping tag extraction"
                group_build_tags="$build_tags"
            fi
            echo "INFO: Group build tags for OCP $group_ocp_version:" \
                "$(echo "${group_build_tags}" | jq -r '.[]' | tr '\n' ' ')"

            # Initialize group-specific tracking for batch chaining
            local group_current_from_index="$group_from_index"
            local group_latest_iib_index_image=""
            local group_failed_batches=()
            local group_successful_batches=()

            # Calculate batches for this group
            local num_components
            num_components=$(echo "$group_components" | jq 'length')
            local group_num_batches=$(( (num_components + MAX_BATCH_SIZE - 1) / MAX_BATCH_SIZE ))

            echo "INFO: Creating $group_num_batches batch(es) for $num_components components" \
                "in OCP group $group_ocp_version"

            # Determine fromIndex for batch chaining
            get_current_from_index() {
                if [ "${mustOverwriteFromIndexImage}" = "true" ]; then
                    # IIB overwrites fromIndex - keep using original consistently
                    printf '%s' "${group_from_index}"
                else
                    # IIB creates new index - we MUST track what was actually created
                    if [ ${#group_successful_batches[@]} -eq 0 ]; then
                        # No successful batches yet - start from original fromIndex
                        printf '%s' "${group_from_index}"
                    else
                        # We have successful batches - MUST use latest IIB output
                        if [ -z "${group_latest_iib_index_image}" ]; then
                            echo "FATAL ERROR: We have successful batches but group_latest_iib_index_image is empty!"
                            echo "This would cause data loss. Group successful batches: ${group_successful_batches[*]}"
                            exit 1
                        fi
                        echo "${group_latest_iib_index_image}"
                    fi
                fi
            }

            # Get batch fragments
            get_batch_fragments() {
                local batch_num="$1"
                local start_idx=$((batch_num * MAX_BATCH_SIZE))
                local end_idx=$(((batch_num + 1) * MAX_BATCH_SIZE))
                local group_length
                group_length=$(echo "$group_components" | jq 'length')
                if [ "$end_idx" -gt "$group_length" ]; then
                    end_idx=$group_length
                fi

                echo "$group_components" | jq -c ".[${start_idx}:${end_idx}] | map(.containerImage)"
            }

            # Execute batch with validation
            execute_batch() {
                local batch_num="$1"
                local from_index="$2"

                echo "Executing group batch $((batch_num + 1)): fromIndex=${from_index}" \
                    "(OCP: $group_ocp_version)"

                # Get batch fragments
                local batch_fragments
                batch_fragments=$(get_batch_fragments "$batch_num")

                # Create InternalRequest for this batch
                internal-request --pipeline "update-fbc-catalog" \
                    -p fromIndex="${from_index}" \
                    -p fbcFragments="$(printf '%s' "${batch_fragments}" | jq -c .)" \
                    -p iibServiceAccountSecret="${iib_service_account_secret}" \
                    -p publishingCredentials="${publishing_credentials}" \
                    -p buildTimeoutSeconds="${build_timeout_seconds}" \
                    -p buildTags="$(jq -c . <<< "${group_build_tags}")" \
                    -p addArches="$(jq -c . <<< "${add_arches}")" \
                    -p mustPublishIndexImage="${mustPublishIndexImage}" \
                    -p mustOverwriteFromIndexImage="${mustOverwriteFromIndexImage}" \
                    -p taskGitUrl="$(params.taskGitUrl)" \
                    -p taskGitRevision="$(params.taskGitRevision)" \
                    --service-account "${internal_request_service_account}" \
                    -l ${TASK_LABEL}="${TASK_ID}" \
                    -l ${PIPELINERUN_LABEL}="$(params.pipelineRunUid)" \
                    --pipeline-timeout "${pipeline_timeout}" \
                    --task-timeout "${task_timeout}" \
                    -t "${request_timeout_seconds}" \
                    | tee "$(params.dataDir)/ir-$(context.taskRun.uid)-batch-$((batch_num + 1))-output.log"

                # Extract request name
                local internalRequest
                internalRequest=$(awk -F"'" '/created/ { print $2 }' \
                    "$(params.dataDir)/ir-$(context.taskRun.uid)-batch-$((batch_num + 1))-output.log")

                # Validate internal request succeeded
                local request_status
                request_status=$(kubectl get internalrequest "${internalRequest}" \
                    -o jsonpath='{.status.conditions[?(@.type=="Succeeded")].status}')

                if [ "${request_status}" != "True" ]; then
                    echo "ERROR: Batch $((batch_num + 1)) internal request failed"
                    local request_reason
                    request_reason=$(kubectl get internalrequest "${internalRequest}" \
                        -o jsonpath='{.status.conditions[?(@.type=="Succeeded")].reason}')
                    local request_message
                    request_message=$(kubectl get internalrequest "${internalRequest}" \
                        -o jsonpath='{.status.conditions[?(@.type=="Succeeded")].message}')
                    echo "Reason: ${request_reason}"
                    echo "Message: ${request_message}"
                    return 1
                fi

                # Extract and validate results
                local results
                results=$(kubectl get internalrequest "${internalRequest}" -o jsonpath='{.status.results}')

                if [ -z "${results}" ] || [ "${results}" = "{}" ]; then
                    echo "ERROR: Batch $((batch_num + 1)) succeeded but returned empty results"
                    return 1
                fi

                # Store results for this batch
                echo "${results}" > "$(params.dataDir)/ir-$(context.taskRun.uid)-batch-$((batch_num + 1))-result.json"

                # Process results for each fragment in this batch
                local decompressed_json_build_info
                decompressed_json_build_info="$(jq -r '.jsonBuildInfo' <<< "${results}" | base64 -d | gunzip)"
                local completion_time_raw
                completion_time_raw="$(jq -r '.updated' <<< "${decompressed_json_build_info}")"
                local completion_time
                completion_time=$(date +"${timestamp_format}" -d "${completion_time_raw}")

                # Process fragments in batch
                local fragment_index=0
                echo "$batch_fragments" | jq -r '.[]' | while read -r fragment; do
                    echo "Processing result for fragment: $fragment" \
                        "(group batch $((batch_num + 1)), OCP: $group_ocp_version)"

                    # Build individual component result
                    local build_results
                    build_results=$(jq \
                      --arg fragment "$fragment" \
                      --arg target_index "$group_target_index" \
                      --arg ocp_version "$group_ocp_version" \
                      --arg completion_time "$completion_time" \
                      --argjson decompressed_json "${decompressed_json_build_info}" \
                    '{
                      "fbc_fragment": $fragment,
                      "target_index": $target_index,
                      "ocp_version": $ocp_version,
                      "image_digests": (.indexImageDigests | split(" ") | del(.[] | select(. == ""))),
                      "index_image": $decompressed_json.index_image,
                      "index_image_resolved": $decompressed_json.index_image_resolved,
                      "completion_time": $completion_time,
                      "iibLog": .iibLog
                    }' <<< "${results}")

                    # Add to per-worker results file (avoids concurrent write conflicts)
                    export build_results
                    yq -i '.components += [ env(build_results) ]' "$worker_results_file"

                    fragment_index=$((fragment_index + 1))
                done

                echo "Group batch $((batch_num + 1)) completed successfully" \
                    "for OCP $group_ocp_version"
                return 0
            }

            # Execute batches with failure tracking and retry logic
            for((batch_num=0; batch_num<"$group_num_batches"; batch_num++)); do
                echo "Processing group batch $((batch_num + 1))/${group_num_batches}" \
                    "for OCP $group_ocp_version..."

                group_current_from_index=$(get_current_from_index)

                  if execute_batch "$batch_num" "$group_current_from_index"; then
                    group_successful_batches+=("$batch_num")
                    echo "Group batch $((batch_num + 1)) succeeded for OCP $group_ocp_version"

                    # Extract latest IIB index image for next batch (only when not overwriting)
                    if [ "${mustOverwriteFromIndexImage}" = "false" ]; then
                        result_file="$(params.dataDir)/ir-$(context.taskRun.uid)-batch-$((batch_num + 1))-result.json"
                        batch_results=$(cat "${result_file}")
                        group_latest_iib_index_image=$(jq -r '.jsonBuildInfo' <<< "${batch_results}" | \
                            base64 -d | gunzip | jq -r '.index_image')
                        echo "Updated fromIndex for next batch: ${group_latest_iib_index_image}"
                    fi
                else
                    group_failed_batches+=("$batch_num")
                    echo "Group batch $((batch_num + 1)) failed, will retry later for OCP $group_ocp_version"
                    # Continue with next batch - no dependency blocking
                fi
            done

            # Retry failed batches (order doesn't matter)
            local max_retries
            max_retries=$(params.maxRetries)
            local batch_retry_delay
            batch_retry_delay=$(params.batchRetryDelaySeconds)

            for retry_attempt in $(seq 1 "$max_retries"); do
                if [ ${#group_failed_batches[@]} -eq 0 ]; then
                    echo "All group batches completed successfully for OCP $group_ocp_version"
                    break
                fi

                echo "Retry attempt ${retry_attempt}: ${#group_failed_batches[@]} group batches" \
                    "to retry for OCP $group_ocp_version"
                local still_failed=()

                for batch_num in "${group_failed_batches[@]}"; do
                    group_current_from_index=$(get_current_from_index)

                    if execute_batch "$batch_num" "$group_current_from_index" \
                        "$group_target_index"; then
                        echo "Group batch $((batch_num + 1)) succeeded on retry attempt ${retry_attempt}" \
                            "for OCP $group_ocp_version"

                        # Add to successful batches and extract latest IIB index image (only when not overwriting)
                        group_successful_batches+=("$batch_num")
                        if [ "${mustOverwriteFromIndexImage}" = "false" ]; then
                            result_file="$(params.dataDir)/ir-$(context.taskRun.uid)" \
                                "-batch-$((batch_num + 1))-result.json"
                            batch_results=$(cat "${result_file}")
                            group_latest_iib_index_image=$(jq -r '.jsonBuildInfo' <<< "${batch_results}" | \
                                base64 -d | gunzip | jq -r '.index_image')
                            echo "Updated fromIndex for next batch: ${group_latest_iib_index_image}"
                        fi
                    else
                        still_failed+=("$batch_num")
                        echo "Group batch $((batch_num + 1)) failed retry attempt ${retry_attempt}" \
                            "for OCP $group_ocp_version"
                    fi
                done

                group_failed_batches=("${still_failed[@]}")

                if [ ${#group_failed_batches[@]} -gt 0 ] && [ "${retry_attempt}" -lt "${max_retries}" ]; then
                    echo "Waiting ${batch_retry_delay} seconds before next retry attempt..."
                    sleep "${batch_retry_delay}"
                fi
            done

            # Final validation to ensure all components were processed
            if [ ${#group_failed_batches[@]} -gt 0 ]; then
                echo "ERROR: ${#group_failed_batches[@]} group batches failed after all retries" \
                    "for OCP $group_ocp_version:"
                for batch_num in "${group_failed_batches[@]}"; do
                    echo "  - Group batch $((batch_num + 1))"
                done
                echo "Cannot proceed with partial index for OCP $group_ocp_version -" \
                    "this would result in incomplete fragment coverage"
                exit 1
            fi

            echo "SUCCESS: All ${group_num_batches} group batches completed" \
                "successfully for OCP $group_ocp_version"
        }

        # Execute the multi-OCP processing
        process_all_ocp_groups

        # Classify the targets by `target_index`, but if this is a staging build, we should classify
        # the targets by `ocp_version` instead, as `target_index` will be missing for this case.
        UNIQUE_TARGETS=$(jq -r '[.components[].target_index] | unique | length' "$RESULTS_FILE")

        isStage=$(jq '.fbc.stagedIndex // false' "${DATA_FILE}")
        if [ "${isStage}" == "true" ]; then
          UNIQUE_TARGETS=$(jq -r '[.components[].ocp_version] | unique | length' "$RESULTS_FILE")
        fi

        # Deduplicate results: keep only the last component per unique target_index (the last one), or
        # by ocp_version when target_index is set to an empty string.
        # This ensures downstream tasks (collect-index-images, create-pyxis-image) use the correct digest.
        TOTAL_COMPONENTS=$(jq -r '.components | length' "$RESULTS_FILE")
        if [[ "$TOTAL_COMPONENTS" -gt "$UNIQUE_TARGETS" ]]; then
          echo "Found $TOTAL_COMPONENTS components for $UNIQUE_TARGETS unique targets"
          echo "Keeping only the last (most recent) index for each OCP target"

          RESULTS_TEMP_FILE="/tmp/results-temp.json"
          jq '[
            .components
              | group_by(
                  (.target_index | select(.!="")) // .ocp_version
                )
              | .[] | last ]
              | { components: . }' "$RESULTS_FILE" | tee "$RESULTS_TEMP_FILE"

          mv "$RESULTS_TEMP_FILE" "$RESULTS_FILE"

          DEDUPLICATED_COUNT=$(jq -r '.components | length' "$RESULTS_FILE")
          echo "Deduplicated from $TOTAL_COMPONENTS to $DEDUPLICATED_COUNT components"
        else
          echo "No deduplication needed ($TOTAL_COMPONENTS components, $UNIQUE_TARGETS unique targets)"
        fi

        # Get the final batch result for legacy compatibility (use last successful batch from any group)
        # Find the most recent batch result file
        latest_result_file=$(find "$(params.dataDir)" -name "ir-*-batch-*-result.json" \
            -type f -exec ls -t {} + 2>/dev/null | head -1)
        if [[ -n "$latest_result_file" ]]; then
            results=$(cat "$latest_result_file")
            # Extract batch number from filename for output log
            batch_number=$(basename "$latest_result_file" | sed 's/.*-batch-\([0-9]*\)-result.json/\1/')
            internalRequest=$(awk -F"'" '/created/ { print $2 }' \
                "$(params.dataDir)/ir-$(context.taskRun.uid)-batch-${batch_number}-output.log")
        else
            echo "ERROR: No batch result files found"
            exit 1
        fi

        echo "Final publishing and compatibility values:"
        echo "  - mustPublishIndexImage: ${mustPublishIndexImage}"

        # Output batch logs for debugging
        jq -r '.iibLog' <<< "${results}"
        RC="$(jq -r '.exitCode' <<< "${results}")"

        # Summarize batch results
        if [ "$mustPublishIndexImage" = "true" ]; then
          echo "Index image will be published."
        else
          echo "Index image will not be published (decision made by prepare-fbc-parameters)."
        fi

        if [ "$RC" -ne 0 ]; then
          echo "Batch processing failed, check the batch logs above to understand the reason"
          exit "$RC"
        fi

        # Calculate total components processed across all OCP groups
        total_components=$(jq '.components | length' "$SNAPSHOT_PATH")
        echo "Multi-OCP batch processing completed successfully with $total_components components" \
            "across ${#ocp_versions_array[@]} OCP versions"
        echo "Results file:"
        cat "$RESULTS_FILE"
    - name: create-trusted-artifact
      computeResources:
        limits:
          memory: 128Mi
        requests:
          memory: 128Mi
          cpu: 250m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/create-trusted-artifact/create-trusted-artifact.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(results.sourceDataArtifact.path)
