---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: push-artifacts-to-cdn-task
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: |-
    Tekton task to push artifacts to the Customer Portal using Pulp and optionally to
    the Developer Portal using exodus-rsync with optional signing. It uses logic based
    on the snapshot data to determine which targets to publish to: if components contain
    both `staged` and `contentGateway` data, artifacts are pushed to the Customer Portal
    (Pulp) and to CGW; if components contain `staged` data only, artifacts are
    pushed to the Customer Portal (Pulp); if components contain `contentGateway`
    data only, artifacts are pushed to the Developer Portal (exodus-rsync) and CGW.
  params:
    - name: snapshot_json
      type: string
      description: String containing a JSON representation of the snapshot spec
    - name: concurrentLimit
      type: string
      description: The maximum number of images to be pulled at once
      default: 3
    # signing params start here
    - name: author
      type: string
      description: Author taken from Release to be used for checksum signing
    - name: signingKeyName
      type: string
      description: Signing key name to be used for checksum signing
    - name: quayURL
      type: string
      description: Quay URL of the repo where content will be shared between tasks
      default: quay.io/konflux-artifacts
    - name: quaySecret
      type: string
      description: Secret to interact with Quay
      default: quay-credentials
    - name: windowsCredentials
      type: string
      description: Secret to interact with the Windows signing host
      default: windows-credentials
    - name: windowsSSHKey
      type: string
      description: Secret containing SSH private key for the Windows signing host
      default: windows-ssh-key
    - name: macHostCredentials
      type: string
      description: Secret to interact with the Mac signing host
      default: mac-host-credentials
    - name: macSigningCredentials
      type: string
      description: Secret to interact with the Mac signing utils
      default: mac-signing-credentials
    - name: macSSHKey
      type: string
      description: Secret containing SSH private key for the Mac signing host
      default: mac-ssh-key
    - name: checksumCredentials
      type: string
      description: Secret containing the keytab, user, host, and fingerprint for the checksum host
      default: checksum-credentials
    - name: kerberosRealm
      type: string
      description: Kerberos realm for the checksum host
      default: IPA.REDHAT.COM
    # cdn params start here
    - name: exodusGwSecret
      type: string
      description: Env specific secret containing the Exodus Gateway configs
    - name: exodusGwEnv
      type: string
      description: Environment to use in the Exodus Gateway. Options are [live, pre]
    - name: pulpSecret
      type: string
      description: Env specific secret containing the rhsm-pulp credentials
    - name: udcacheSecret
      type: string
      description: Env specific secret containing the udcache credentials
    - name: cgwHostname
      type: string
      description: Env specific hostname for content gateway
    - name: cgwSecret
      type: string
      description: Env specific secret containing the content gateway credentials
    - name: caTrustConfigMapName
      type: string
      description: The name of the ConfigMap to read CA bundle data from
      default: trusted-ca
    - name: caTrustConfigMapKey
      type: string
      description: The name of the key in the ConfigMap that contains the CA bundle data
      default: ca-bundle.crt
    - name: certExpirationWarnDays
      type: string
      description: Number of days before expiration to warn about certificate expiration
      default: "7"
  results:
    - name: result
      description: Success if the task succeeds, the error otherwise
    - name: publishedFiles
      description: List of published files
  volumes:
    - name: shared-dir
      emptyDir: {}
    - name: mac-ssh-key-vol
      secret:
        secretName: mac-ssh-key
        defaultMode: 0444
    - name: windows-ssh-key-vol
      secret:
        secretName: windows-ssh-key
        defaultMode: 0444
    - name: checksum-credentials-vol
      secret:
        secretName: $(params.checksumCredentials)
        defaultMode: 0444
    - name: redhat-workloads-token
      secret:
        secretName: redhat-workloads-token
        defaultMode: 0444
    - name: quay-secret
      secret:
        secretName: $(params.quaySecret)
        defaultMode: 0444
    - name: mac-host-credentials
      secret:
        secretName: $(params.macHostCredentials)
        defaultMode: 0444
    - name: mac-signing-credentials
      secret:
        secretName: $(params.macSigningCredentials)
        defaultMode: 0444
    - name: windows-credentials
      secret:
        secretName: $(params.windowsCredentials)
        defaultMode: 0444
    - name: exodus-gw-secret
      secret:
        secretName: $(params.exodusGwSecret)
        defaultMode: 0444
    - name: pulp-secret
      secret:
        secretName: $(params.pulpSecret)
        defaultMode: 0444
    - name: udcache-secret
      secret:
        secretName: $(params.udcacheSecret)
        defaultMode: 0444
    - name: cgw-secret
      secret:
        secretName: $(params.cgwSecret)
        defaultMode: 0444
    - name: trusted-ca
      configMap:
        name: $(params.caTrustConfigMapName)
        items:
          - key: $(params.caTrustConfigMapKey)
            path: ca-bundle.crt
        optional: true
  stepTemplate:
    volumeMounts:
      - name: trusted-ca
        mountPath: /mnt/trusted-ca
        readOnly: true

  steps:
    - name: extract-artifacts
      image: quay.io/konflux-ci/release-service-utils:82012e03002128f2a226acb23dc5c6fc1c37f5b6
      securityContext:
        runAsUser: 1001
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: redhat-workloads-token
          mountPath: /mnt/redhat-workloads-token
      env:
        - name: "SNAPSHOT_JSON"
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -e

        DOCKER_CONFIG_JSON="$(cat /mnt/redhat-workloads-token/.dockerconfigjson)"

        set -x

        STDERR_FILE=/tmp/stderr.txt

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        mkdir -p ~/.docker
        set +x
        # Quotes are added to the secret so it applies in k8s nicely. But now we have to remove them
        echo "$DOCKER_CONFIG_JSON" | sed -r 's/(^|\})[^{}]+(\{|$)/\1\2/g' > ~/.docker/config.json
        set -x

        CONTENT_DIR="/shared/artifacts"
        export CONTENT_DIR
        mkdir -p "$CONTENT_DIR"

        process_component() { # Expected arguments: [component json] [component index (0-based)]
            COMPONENT=$1
            COMPONENT_INDEX=$2
            COMPONENT_NUM=$((COMPONENT_INDEX + 1))  # 1-based for error messages
            # Use component.name for directory isolation
            COMPONENT_NAME=$(jq -er '.name' <<< "${COMPONENT}") \
                  || (echo "Component ${COMPONENT_NUM} is missing 'name'" >&2 && exit 1 )
            
            # Check if component has files or staged.files - skip if neither exists
            NUM_FILES=$(jq '.files | length // 0' <<< "${COMPONENT}")
            NUM_STAGED_FILES=$(jq '.staged.files | length // 0' <<< "${COMPONENT}")
            if [ "$NUM_FILES" -eq 0 ] && [ "$NUM_STAGED_FILES" -eq 0 ]; then
              echo "Skipping component '${COMPONENT_NAME}' - no files defined (not a binary artifact component)"
              return 0
            fi
            
            PULLSPEC=$(jq -er '.containerImage' <<< "${COMPONENT}") \
                  || (echo "Component ${COMPONENT_NAME} is missing 'containerImage'" >&2 && exit 1 )
            DESTINATION="${CONTENT_DIR}/${COMPONENT_NAME}"
            echo "Extracting component '${COMPONENT_NAME}' to: $DESTINATION"

            mkdir -p "${DESTINATION}"

            # Extract binaries from container image using skopeo (like extract-binaries-from-image task)
            TMP_DIR=$(mktemp -d)

            # Create auth file for skopeo
            AUTH_FILE=$(mktemp)
            select-oci-auth "${PULLSPEC}" > "$AUTH_FILE"

            # Use skopeo to copy container manifest and layers
            skopeo copy --retry-times 3 --authfile "$AUTH_FILE" docker://"$PULLSPEC" dir:"$TMP_DIR"

            cd "$TMP_DIR"

            # Build list of specific files to extract from files[] and staged.files[]
            # We only want files explicitly listed in the RPA, not everything in the container
            WANTED_FILES=()
            EXTRACT_DIRS=()

            # Check .files[].source paths
            NUM_FILES=$(jq '.files | length // 0' <<< "${COMPONENT}")
            for ((i = 0; i < NUM_FILES; i++)); do
                SOURCE_PATH=$(jq -r --arg i "$i" '.files[$i|tonumber].source // empty' <<< "${COMPONENT}")
                if [ -n "$SOURCE_PATH" ]; then
                    # Store the full path (without leading /) for extraction
                    WANTED_FILES+=("${SOURCE_PATH#/}")
                    # Extract directory part for tar extraction
                    DIR_PATH=$(dirname "$SOURCE_PATH" | sed 's|^/||')
                    if [ "$DIR_PATH" != "." ] && [ -n "$DIR_PATH" ]; then
                        EXTRACT_DIRS+=("$DIR_PATH")
                    fi
                fi
            done

            # Check .staged.files[].source paths
            NUM_STAGED_FILES=$(jq '.staged.files | length // 0' <<< "${COMPONENT}")
            for ((i = 0; i < NUM_STAGED_FILES; i++)); do
                SOURCE_PATH=$(jq -r --arg i "$i" '.staged.files[$i|tonumber].source // empty' <<< "${COMPONENT}")
                if [ -n "$SOURCE_PATH" ]; then
                    # Store the full path (without leading /) for extraction
                    WANTED_FILES+=("${SOURCE_PATH#/}")
                    # Extract directory part for tar extraction
                    DIR_PATH=$(dirname "$SOURCE_PATH" | sed 's|^/||')
                    if [ "$DIR_PATH" != "." ] && [ -n "$DIR_PATH" ]; then
                        EXTRACT_DIRS+=("$DIR_PATH")
                    fi
                fi
            done

            # Default to "releases" if no source directories found
            if [ ${#EXTRACT_DIRS[@]} -eq 0 ]; then
                EXTRACT_DIRS=("releases")
            fi

            # Remove duplicates
            mapfile -t UNIQUE_DIRS < <(printf "%s\n" "${EXTRACT_DIRS[@]}" | sort -u)
            mapfile -t UNIQUE_FILES < <(printf "%s\n" "${WANTED_FILES[@]}" | sort -u)

            echo "Files to extract from RPA: ${UNIQUE_FILES[*]}"

            # Extract the directories from container layers
            for IMAGE_PATH in "${UNIQUE_DIRS[@]}"; do
                echo "Looking for directory: $IMAGE_PATH"
                for DIGEST in $(jq -r ".layers[].digest" manifest.json); do
                    FILE=${DIGEST#sha256:}
                    # Check if the archive contains the target dir
                    if tar -tf "$FILE" | grep -q "^$IMAGE_PATH/"; then
                        echo "Extracting $IMAGE_PATH/ from $FILE..."
                        tar -xzvf "$FILE" "$IMAGE_PATH"
                    else
                        echo "skipping $FILE. It doesn't contain the $IMAGE_PATH dir"
                    fi
                done
            done

            # Copy ONLY files explicitly listed in the RPA (not all files from the directory)
            for wanted_file in "${UNIQUE_FILES[@]}"; do
                if [ -f "$wanted_file" ]; then
                    cp "$wanted_file" "$DESTINATION"/
                else
                    echo "Warning: Expected file not found in container: $wanted_file"
                fi
            done

            # Clean up temporary directory
            rm -rf "$TMP_DIR"

        }

        RUNNING_JOBS="\j" # Bash parameter for number of jobs currently running
        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")

        # Pull each component in parallel
        for ((i = 0; i < NUM_COMPONENTS; i++)) ; do
            COMPONENT=$(jq -c --arg i "$i" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
            # Limit batch size to concurrent limit
            while (( ${RUNNING_JOBS@P} >= $(params.concurrentLimit) )); do
                wait -n
            done
            process_component "$COMPONENT" "$i" 2> "$STDERR_FILE" &
        done

        # Wait for remaining processes to finish
        while (( ${RUNNING_JOBS@P} > 0 )); do
            wait -n
        done

        # Create flag files based on OS types specified in the RPA mapping (files array)
        # This ensures we only process OS types that are configured for release, not everything in the container
        FILES_QUERY='(.files[]?, .staged.files[]?)'
        for ((i = 0; i < NUM_COMPONENTS; i++)); do
          COMPONENT=$(jq -c --arg i "$i" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
          COMPONENT_NAME=$(jq -r '.name' <<< "$COMPONENT")
          component_dir="$CONTENT_DIR/$COMPONENT_NAME"
          
          echo "Checking configured OS types for component: $COMPONENT_NAME"
          
          # Check for macOS(darwin) in both .files[] and .staged.files[]
          if jq -e "$FILES_QUERY | select(.os == \"darwin\")" <<< "$COMPONENT" >/dev/null 2>&1 || \
             jq -e "$FILES_QUERY | select((.source // \"\") | contains(\"darwin\"))" \
               <<< "$COMPONENT" >/dev/null 2>&1 || \
             jq -e "$FILES_QUERY | select((.filename // \"\") | contains(\"darwin\"))" \
               <<< "$COMPONENT" >/dev/null 2>&1; then
            touch "$component_dir/has_mac"
            echo "  - macOS content detected"
          fi
          # Check for Windows in both .files[] and .staged.files[]
          if jq -e "$FILES_QUERY | select(.os == \"windows\")" <<< "$COMPONENT" >/dev/null 2>&1 || \
             jq -e "$FILES_QUERY | select((.source // \"\") | contains(\"windows\"))" \
               <<< "$COMPONENT" >/dev/null 2>&1 || \
             jq -e "$FILES_QUERY | select((.filename // \"\") | contains(\"windows\"))" \
               <<< "$COMPONENT" >/dev/null 2>&1; then
            touch "$component_dir/has_windows"
            echo "  - Windows content detected"
          fi
          # Check for Linux in both .files[] and .staged.files[]
          if jq -e "$FILES_QUERY | select(.os == \"linux\")" <<< "$COMPONENT" >/dev/null 2>&1 || \
             jq -e "$FILES_QUERY | select((.source // \"\") | contains(\"linux\"))" \
               <<< "$COMPONENT" >/dev/null 2>&1 || \
             jq -e "$FILES_QUERY | select((.filename // \"\") | contains(\"linux\"))" \
               <<< "$COMPONENT" >/dev/null 2>&1; then
            touch "$component_dir/has_linux"
            echo "  - Linux content detected"
          fi
        done
    - name: push-unsigned-using-oras
      image: quay.io/konflux-ci/release-service-utils:82012e03002128f2a226acb23dc5c6fc1c37f5b6
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: quay-secret
          mountPath: /mnt/quaySecret
      env:
        - name: SNAPSHOT_JSON
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -eu

        QUAY_USER="$(cat "/mnt/quaySecret/username")"
        QUAY_PASS="$(cat "/mnt/quaySecret/password")"

        set -x

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        CONTENT_DIR=/shared/artifacts

        echo "Logging into Quay..."
        set +x
        oras login quay.io -u "${QUAY_USER}" -p "${QUAY_PASS}" > /dev/null 2>&1
        set -x

        # Process each component separately
        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")
        for ((c = 0; c < NUM_COMPONENTS; c++)); do
          COMPONENT=$(jq -c --arg i "$c" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
          COMPONENT_NAME=$(jq -r '.name' <<< "$COMPONENT")
          
          echo "Processing component: $COMPONENT_NAME"
          
          # Skip components without files or staged.files (not binary artifact components)
          NUM_FILES=$(jq '.files | length // 0' <<< "$COMPONENT")
          NUM_STAGED_FILES=$(jq '.staged.files | length // 0' <<< "$COMPONENT")
          if [ "$NUM_FILES" -eq 0 ] && [ "$NUM_STAGED_FILES" -eq 0 ]; then
            echo "Skipping component '$COMPONENT_NAME' - no files or staged.files defined"
            continue
          fi
          
          COMPONENT_DIR="$CONTENT_DIR/$COMPONENT_NAME"
          UNSIGNED_DIR="$COMPONENT_DIR/unsigned"
          MAC_CONTENT="$UNSIGNED_DIR/macos"
          WINDOWS_CONTENT="$UNSIGNED_DIR/windows"
          LINUX_CONTENT="$COMPONENT_DIR/linux"

          # Create directories only for OS types that have content (based on flag files from extract step)
          [ -f "$COMPONENT_DIR/has_mac" ] && mkdir -p "$MAC_CONTENT"
          [ -f "$COMPONENT_DIR/has_windows" ] && mkdir -p "$WINDOWS_CONTENT"
          [ -f "$COMPONENT_DIR/has_linux" ] && mkdir -p "$LINUX_CONTENT"

          # First unpack all archives in place (removing the archives)
          # Note: The || true prevents the while loop's exit code (1 from read at EOF) from triggering set -e
          find "$COMPONENT_DIR" -maxdepth 1 -type f -iregex ".*\.zip\|.*\.gz" 2>/dev/null | while read -r file; do
            dir=$(dirname "$file")
            case "$file" in
              (*.tar.gz)
                tar -xzf "$file" -C "$dir" && rm "$file"
                ;;
              (*.gz)
                gzip -d "$file"
                ;;
              (*.zip)
                unzip "$file" -d "$dir" && rm "$file"
                ;;
            esac
          done || true

          # Then move unpacked files to appropriate directories based on OS
          # Note: Skip has_* flag files - they must stay in the component root directory
          # Only move files if the target directory exists (i.e., that OS type is configured in RPA)
          # Note: The || true at the end prevents the while loop's exit code from triggering set -e
          find "$COMPONENT_DIR" -maxdepth 1 -type f 2>/dev/null | while read -r file; do
            case "$file" in
              (*/has_mac)
                # Skip flag files - they need to stay in the component root directory
                ;;
              (*/has_windows)
                # Skip flag files - they need to stay in the component root directory
                ;;
              (*/has_linux)
                # Skip flag files - they need to stay in the component root directory
                ;;
              (*darwin*)
                [ -d "$MAC_CONTENT" ] && mv "$file" "$MAC_CONTENT/"
                ;;
              (*windows*)
                [ -d "$WINDOWS_CONTENT" ] && mv "$file" "$WINDOWS_CONTENT/"
                ;;
              (*linux*)
                [ -d "$LINUX_CONTENT" ] && mv "$file" "$LINUX_CONTENT/"
                ;;
            esac
          done || true

          # Push unsigned Mac content
          if [ -f "$COMPONENT_DIR/has_mac" ]; then
            pushd "$UNSIGNED_DIR" > /dev/null
            echo "Pushing unsigned Macos content for $COMPONENT_NAME to $(params.quayURL)..."
            output=$(oras push "$(params.quayURL)/${COMPONENT_NAME}/unsigned" macos)
            mac_digest=$(echo "$output" | grep 'Digest:' | awk '{print $2}')
            echo "Digest for $COMPONENT_NAME mac content: $mac_digest"
            echo -n "$mac_digest" > "$COMPONENT_DIR/unsigned_mac_digest.txt"
            popd > /dev/null
          else
            echo "No macOS content for $COMPONENT_NAME, skipping unsigned push..."
          fi

          # Push unsigned Windows content
          if [ -f "$COMPONENT_DIR/has_windows" ]; then
            pushd "$UNSIGNED_DIR" > /dev/null
            echo "Pushing unsigned Windows content for $COMPONENT_NAME to $(params.quayURL)..."
            output=$(oras push "$(params.quayURL)/${COMPONENT_NAME}/unsigned" windows)
            windows_digest=$(echo "$output" | grep 'Digest:' | awk '{print $2}')
            echo "Digest for $COMPONENT_NAME windows content: $windows_digest"
            echo -n "$windows_digest" > "$COMPONENT_DIR/unsigned_windows_digest.txt"
            popd > /dev/null
          else
            echo "No Windows content for $COMPONENT_NAME, skipping unsigned push..."
          fi
        done
    - name: sign-mac-binaries
      image: quay.io/konflux-ci/release-service-utils:82012e03002128f2a226acb23dc5c6fc1c37f5b6
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: mac-ssh-key-vol
          mountPath: "/mnt/secrets"
        - name: quay-secret
          mountPath: /mnt/quaySecret
        - name: mac-host-credentials
          mountPath: /mnt/macHostCredentials
        - name: mac-signing-credentials
          mountPath: /mnt/macSigningCredentials
      env:
        - name: QUAY_URL
          value: $(params.quayURL)
        - name: PIPELINE_UID
          value: $(context.taskRun.uid)
        - name: SNAPSHOT_JSON
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -eu

        MAC_USER="$(cat /mnt/macHostCredentials/username)"
        MAC_HOST="$(cat /mnt/macHostCredentials/host)"
        KEYCHAIN_PASSWORD="$(cat /mnt/macSigningCredentials/keychain_password)"
        SIGNING_IDENTITY="$(cat /mnt/macSigningCredentials/signing_identity)"
        APPLE_ID="$(cat /mnt/macSigningCredentials/apple_id)"
        TEAM_ID="$(cat /mnt/macSigningCredentials/team_id)"
        APP_SPECIFIC_PASSWORD="$(cat /mnt/macSigningCredentials/app_specific_password)"
        QUAY_USER="$(cat /mnt/quaySecret/username)"
        QUAY_PASS="$(cat /mnt/quaySecret/password)"

        set -x

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        mkdir -p /tmp/.ssh
        chmod 700 /tmp/.ssh
        cp "/mnt/secrets/mac_id_rsa" /tmp/.ssh/id_rsa
        cp "/mnt/secrets/mac_fingerprint" /tmp/.ssh/known_hosts
        chmod 600 /tmp/.ssh/id_rsa /tmp/.ssh/known_hosts

        SSH_OPTS=(-i /tmp/.ssh/id_rsa -o UserKnownHostsFile=/tmp/.ssh/known_hosts -o IdentitiesOnly=yes)

        CONTENT_DIR=/shared/artifacts

        # Process each component sequentially
        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")
        for ((c = 0; c < NUM_COMPONENTS; c++)); do
          COMPONENT=$(jq -c --arg i "$c" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
          COMPONENT_NAME=$(jq -r '.name' <<< "$COMPONENT")
          COMPONENT_DIR="$CONTENT_DIR/$COMPONENT_NAME"

          # Skip if no macOS content for this component
          if [ ! -f "$COMPONENT_DIR/has_mac" ]; then
            echo "No macOS content for component $COMPONENT_NAME, skipping Mac signing..."
            continue
          fi

          echo "Signing Mac binaries for component: $COMPONENT_NAME"

          # Read unsigned digest for this component
          unsigned_digest=$(cat "$COMPONENT_DIR/unsigned_mac_digest.txt")
          mac_signing_script="/tmp/mac_signing_script_$(context.taskRun.uid)_${COMPONENT_NAME}.sh"

          TEMP_DIR="/tmp/$(context.taskRun.uid)_${COMPONENT_NAME}"
          BINARY_PATH="$TEMP_DIR/unsigned/macos"
          ZIP_PATH="$TEMP_DIR/signed_content.zip"
          DIGEST_FILE="$TEMP_DIR/push_digest.txt"

          cat << EOF > "$mac_signing_script"
          #!/bin/bash
          set -eux

          mkdir -p "$TEMP_DIR"
          mkdir -p "$BINARY_PATH"

          cd "$TEMP_DIR"
          set +x
          /usr/local/bin/oras login quay.io -u ${QUAY_USER} -p ${QUAY_PASS}
          set -x
          /usr/local/bin/oras pull $(params.quayURL)/${COMPONENT_NAME}/unsigned@$unsigned_digest -o "$BINARY_PATH"
          # This is the directory where the content was extracted
          CONTENT_DIR_MAC=\$(find "$BINARY_PATH" -maxdepth 1 -type d | tail -n 1)

          set +x
          security unlock-keychain -p $KEYCHAIN_PASSWORD login.keychain
          set -x
          echo "Signing files in the \$CONTENT_DIR_MAC directory..."
          find "\$CONTENT_DIR_MAC" -type f | while read file; do
              echo "Signing: \$file"
              if ! xcrun codesign --sign "Developer ID Application: $SIGNING_IDENTITY" \
                  --options runtime --timestamp --force "\$file"; then
                  echo "Failed to sign file: \$file"
                  exit 1
              fi
          done

          cd "$BINARY_PATH"
          NEW_CONTENT_DIR=\$(basename "\$CONTENT_DIR_MAC")
          zip -r "$ZIP_PATH" "\$NEW_CONTENT_DIR"

          echo "Submitting ZIP file to Apple notary service..."
          set +x
          xcrun notarytool submit "$ZIP_PATH" \
              --wait \
              --apple-id "$APPLE_ID" \
              --team-id "$TEAM_ID" \
              --password "$APP_SPECIFIC_PASSWORD"
          set -x

          SIGNED_TAG="$(context.taskRun.uid)-mac"
          PUSH_OUTPUT=\$(/usr/local/bin/oras push \
            "$QUAY_URL/${COMPONENT_NAME}/signed:\$SIGNED_TAG" "\$NEW_CONTENT_DIR")
          SIGNED_DIGEST=\$(echo "\$PUSH_OUTPUT" | grep 'Digest:' | awk '{print \$2}')
          echo -n "\$SIGNED_DIGEST" >> "$DIGEST_FILE"
          echo "Process completed successfully."
        EOF

          # Copy the script to the Mac host
          scp "${SSH_OPTS[@]}" "$mac_signing_script" "${MAC_USER}@${MAC_HOST}:${mac_signing_script}"

          # Execute the script on the Mac host
          # shellcheck disable=SC2029
          ssh "${SSH_OPTS[@]}" "${MAC_USER}@${MAC_HOST}" bash "${mac_signing_script}"

          # Copy the signed digest back to the shared volume for this component
          scp "${SSH_OPTS[@]}" "${MAC_USER}@${MAC_HOST}:${TEMP_DIR}/push_digest.txt" \
              "$COMPONENT_DIR/signed_mac_digest.txt"

          # Clean up the Mac host now that we are done with this component
          # shell check complains the variables evaluate on the client side, but we want that here
          # shellcheck disable=SC2029
          ssh "${SSH_OPTS[@]}" "${MAC_USER}@${MAC_HOST}" "rm -rf ${TEMP_DIR} ${mac_signing_script}"
        done
    - name: sign-windows-binaries
      image: quay.io/konflux-ci/release-service-utils:82012e03002128f2a226acb23dc5c6fc1c37f5b6
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: windows-ssh-key-vol
          mountPath: /mnt/secrets
        - name: quay-secret
          mountPath: /mnt/quaySecret
        - name: windows-credentials
          mountPath: /mnt/windowsCredentials
      env:
        - name: SNAPSHOT_JSON
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -eu

        WINDOWS_USER="$(cat /mnt/windowsCredentials/username)"
        WINDOWS_PORT="$(cat /mnt/windowsCredentials/port)"
        WINDOWS_HOST="$(cat /mnt/windowsCredentials/host)"
        QUAY_USER="$(cat /mnt/quaySecret/username)"
        QUAY_PASS="$(cat /mnt/quaySecret/password)"

        set -x

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        mkdir -p /tmp/.ssh
        chmod 700 /tmp/.ssh
        cp "/mnt/secrets/windows_id_rsa" /tmp/.ssh/id_rsa
        cp "/mnt/secrets/windows_fingerprint" /tmp/.ssh/known_hosts
        chmod 600 /tmp/.ssh/known_hosts /tmp/.ssh/id_rsa

        SSH_OPTS=(-i /tmp/.ssh/id_rsa -o UserKnownHostsFile=/tmp/.ssh/known_hosts \
          -o IdentitiesOnly=yes -p "${WINDOWS_PORT}")
        SCP_OPTS=(-i /tmp/.ssh/id_rsa -o UserKnownHostsFile=/tmp/.ssh/known_hosts \
          -o IdentitiesOnly=yes -P "${WINDOWS_PORT}")

        CONTENT_DIR=/shared/artifacts

        # Process each component sequentially
        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")
        for ((c = 0; c < NUM_COMPONENTS; c++)); do
          COMPONENT=$(jq -c --arg i "$c" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
          COMPONENT_NAME=$(jq -r '.name' <<< "$COMPONENT")
          COMPONENT_DIR="$CONTENT_DIR/$COMPONENT_NAME"

          # Skip if no Windows content for this component
          if [ ! -f "$COMPONENT_DIR/has_windows" ]; then
            echo "No Windows content for component $COMPONENT_NAME, skipping Windows signing..."
            continue
          fi

          echo "Signing Windows binaries for component: $COMPONENT_NAME"

          # Read unsigned digest for this component
          unsigned_digest=$(cat "$COMPONENT_DIR/unsigned_windows_digest.txt")

          # Create the batch script
          windows_signing_script_file="/tmp/windows_signing_script_file_$(context.taskRun.uid)_${COMPONENT_NAME}.bat"
          WINDOWS_TEMP_DIR="$(context.taskRun.uid)_${COMPONENT_NAME}"
          WIN_TEMP="C:/Users/${WINDOWS_USER}/AppData/Local/Temp"
          WINDOWS_SIGNING_SCRIPT_PATH="${WIN_TEMP}/windows_signing_script_file_${WINDOWS_TEMP_DIR}.bat"
          set +x
          cat << EOF > "$windows_signing_script_file"

          mkdir %TEMP%\\${WINDOWS_TEMP_DIR} && cd /d %TEMP%\\${WINDOWS_TEMP_DIR}
          @echo off
          oras login quay.io -u ${QUAY_USER} -p ${QUAY_PASS}
          @echo on
          oras pull $(params.quayURL)/${COMPONENT_NAME}/unsigned@${unsigned_digest}

          signtool sign /v /n "Red Hat" /fd SHA256 /tr http://timestamp.digicert.com /td SHA256 ^
          %TEMP%\\${WINDOWS_TEMP_DIR}\\windows\\*

          if errorlevel 1 (
            echo Signing of binaries failed
            exit /B %ERRORLEVEL%
          )

          signtool verify /v /pa %TEMP%\\${WINDOWS_TEMP_DIR}\\windows\\*

          if errorlevel 1 (
            echo Verification of binaries failed
            exit /B %ERRORLEVEL%
          )

          echo [%DATE% %TIME%] Signing of Windows binaries for ${COMPONENT_NAME} completed successfully

          oras push $(params.quayURL)/${COMPONENT_NAME}/signed:$(context.taskRun.uid)-windows windows \
          > oras_push_output.txt 2>&1

          for /f "tokens=2,3 delims=: " %%a in ('findstr "Digest:" oras_push_output.txt') do @echo %%a:%%b > digest.txt
        EOF
          set -x
          # shellcheck disable=SC2086
          scp "${SCP_OPTS[@]}" "$windows_signing_script_file" \
          "${WINDOWS_USER}@${WINDOWS_HOST}:${WINDOWS_SIGNING_SCRIPT_PATH}"

          # Execute the script on the Windows host
          # shellcheck disable=SC2029,SC2086
          ssh "${SSH_OPTS[@]}" "${WINDOWS_USER}@${WINDOWS_HOST}" \
            "${WINDOWS_SIGNING_SCRIPT_PATH}"

          # Copy signed digest back to shared volume for this component
          # shellcheck disable=SC2029,SC2086
          WINDOWS_DIGEST_PATH="C:/Users/${WINDOWS_USER}/AppData/Local/Temp/${WINDOWS_TEMP_DIR}/digest.txt"
          scp "${SCP_OPTS[@]}" "${WINDOWS_USER}@${WINDOWS_HOST}:${WINDOWS_DIGEST_PATH}" \
          "$COMPONENT_DIR/signed_windows_digest.txt"

          # Remove trailing spaces, carriage returns, newlines
          sed -i 's/[[:space:]]*$//; s/\r//g; :a;N;$!ba;s/\n//g' "$COMPONENT_DIR/signed_windows_digest.txt"

          # Clean up the windows host now that we are done with this component
          WINDOWS_CLEANUP_PATH="C:\\Users\\${WINDOWS_USER}\\AppData\\Local\\Temp\\${WINDOWS_TEMP_DIR}"
          # shellcheck disable=SC2029,SC2086
          ssh "${SSH_OPTS[@]}" "${WINDOWS_USER}@${WINDOWS_HOST}" \
            "Remove-Item -LiteralPath ${WINDOWS_CLEANUP_PATH} -Force -Recurse; \
            Remove-Item -LiteralPath ${WINDOWS_SIGNING_SCRIPT_PATH} -Force"
        done
    - name: generate-checksums
      image: quay.io/konflux-ci/release-service-utils:82012e03002128f2a226acb23dc5c6fc1c37f5b6
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: checksum-credentials-vol
          mountPath: /mnt/checksum_credentials
        - name: quay-secret
          mountPath: /mnt/quaySecret
      env:
        - name: AUTHOR
          value: $(params.author)
        - name: SIGNING_KEY_NAME
          value: $(params.signingKeyName)
        - name: SNAPSHOT_JSON
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -eu

        QUAY_USER="$(cat /mnt/quaySecret/username)"
        QUAY_PASS="$(cat /mnt/quaySecret/password)"

        set -x

        #---------------------------------------------------------------------------------------
        # This step generates checksums for all of the binaries in the content directory and
        # signs them using the checksum host.
        # The general workflow is that the binaries are extracted from the image(previous task),
        # signed on remote hosts (windows and mac) and then a sha256sum is generated for each
        # binary. The shasums are collected in a sha256sum.txt file which is then transferred to
        # the checksum host for signing with Red Hat's GPG key.
        # The detached signatures are returned to the workspace for inclusion in the later tasks
        # to be pushed to CDN and the Red Hat Developer Portal.
        #---------------------------------------------------------------------------------------

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        if [[ ${AUTHOR} == "" ]] ; then
          echo Error: invalid author
          exit 1
        fi

        SSH_OPTS="-o UserKnownHostsFile=/tmp/.ssh/known_hosts \
                    -o GSSAPIAuthentication=yes \
                    -o GSSAPIDelegateCredentials=yes \
                    -o IdentitiesOnly=yes"

        # Read checksum configuration from secret
        checksum_user=$(cat /mnt/checksum_credentials/user)
        checksum_host=$(cat /mnt/checksum_credentials/host)

        sign_file() {
            local component_name=$1
            local sign_method=$2  # The signing method: --clearsign or --gpgsign
            local extension=$3
            pipeline_run_uid=$(context.taskRun.uid)
            output_path="/home/$checksum_user/${pipeline_run_uid}_${component_name}/checksum/sha256sum.txt.$extension"
            input_file="/home/$checksum_user/${pipeline_run_uid}_${component_name}/checksum/sha256sum.txt"

            echo "Executing SSH command with sign method: $sign_method for component: $component_name"
            # shellcheck disable=SC2029,SC2086
            ssh $SSH_OPTS "$checksum_user@$checksum_host" \
            "rpm-sign --nat $sign_method --key $SIGNING_KEY_NAME --onbehalfof=$AUTHOR \
            --output $output_path $input_file"
        }

        # Generate a kerberos ticket to ssh to the checksum host.
        # The ticket is required for interacting with rpm-sign as well,
        # so we use GSSAPI Delegate (in ssh opts) to transfer the ticket to the checksum host
        KRB5CCNAME=FILE:/tmp/krb5cc_$(id -u)
        export KRB5CCNAME
        base64 -d /mnt/checksum_credentials/keytab > /tmp/sa.keytab
        retry 5 kinit -kt /tmp/sa.keytab "${checksum_user}@$(params.kerberosRealm)"

        mkdir -p /tmp/.ssh
        chmod 700 /tmp/.ssh
        cp "/mnt/checksum_credentials/fingerprint" /tmp/.ssh/known_hosts
        chmod 600 /tmp/.ssh/known_hosts

        CONTENT_DIR=/shared/artifacts

        set +x
        oras login quay.io -u "$QUAY_USER" -p "$QUAY_PASS"
        set -x

        # Process each component separately
        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")
        for ((c = 0; c < NUM_COMPONENTS; c++)); do
          COMPONENT=$(jq -c --arg i "$c" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
          COMPONENT_NAME=$(jq -r '.name' <<< "$COMPONENT")
          COMPONENT_DIR="$CONTENT_DIR/$COMPONENT_NAME"

          echo "Generating checksums for component: $COMPONENT_NAME"

          # Create signed directory structure for this component
          SIGNED_DIR="$COMPONENT_DIR/signed"
          mkdir -p "$SIGNED_DIR"

          # Copy linux files to signed directory (if linux content exists)
          if [ -f "$COMPONENT_DIR/has_linux" ]; then
            mkdir -p "$SIGNED_DIR/linux"
            cp -r "$COMPONENT_DIR/linux/"* "$SIGNED_DIR/linux/" 2>/dev/null || true
          fi

          cd "$SIGNED_DIR"

          # Pull signed Mac binaries for this component (if mac content exists)
          if [ -f "$COMPONENT_DIR/has_mac" ]; then
            mkdir -p "$SIGNED_DIR/macos"
            signed_mac_digest=$(cat "$COMPONENT_DIR/signed_mac_digest.txt")
            # shellcheck disable=SC2086
            oras pull "$(params.quayURL)/${COMPONENT_NAME}/signed@${signed_mac_digest}" -o macos
          fi

          # Pull signed Windows binaries for this component (if windows content exists)
          if [ -f "$COMPONENT_DIR/has_windows" ]; then
            mkdir -p "$SIGNED_DIR/windows"
            signed_windows_digest=$(cat "$COMPONENT_DIR/signed_windows_digest.txt")
            signed_windows_digest=${signed_windows_digest//[[:space:]]/}
            # shellcheck disable=SC2086
            oras pull "$(params.quayURL)/${COMPONENT_NAME}/signed@${signed_windows_digest}" -o windows
          fi

          # Generate checksums for all binaries in this component's signed directory
          SHA_SUM_PATH="$SIGNED_DIR/sha256sum.txt"
          touch "$SHA_SUM_PATH"
          # Build a list of platform directories (macos, windows, linux) that exist
          # conditional on the os directories being present (-d "macos")
          CHECKSUM_DIRS=""
          [ -d "macos" ] && CHECKSUM_DIRS="$CHECKSUM_DIRS macos"
          [ -d "windows" ] && CHECKSUM_DIRS="$CHECKSUM_DIRS windows"
          [ -d "linux" ] && CHECKSUM_DIRS="$CHECKSUM_DIRS linux"
          
          if [ -n "$CHECKSUM_DIRS" ]; then
            # shellcheck disable=SC2086
            find $CHECKSUM_DIRS -type f 2>/dev/null | while read -r file; do
                checksum=$(sha256sum "$file" | awk '{ print $1 }')
                echo "$checksum  $file" >> "$SHA_SUM_PATH"
            done
          fi

          # Send sha256sum.txt to the checksum host for signing (component-specific path)
          REMOTE_DIR="$(context.taskRun.uid)_${COMPONENT_NAME}"
          # shellcheck disable=SC2029,SC2086
          ssh $SSH_OPTS "${checksum_user}@${checksum_host}" "mkdir -p ~/${REMOTE_DIR}/checksum"
          # shellcheck disable=SC2086
          scp $SSH_OPTS "${SHA_SUM_PATH}" \
          "${checksum_user}@${checksum_host}:~/${REMOTE_DIR}/checksum"

          sign_file "$COMPONENT_NAME" --clearsign sig
          sign_file "$COMPONENT_NAME" --gpgsign gpg

          # Copy the signed checksum files back
          scp "$SSH_OPTS" \
          "${checksum_user}@${checksum_host}:~/${REMOTE_DIR}/checksum/sha256sum.txt.sig" \
          "${SIGNED_DIR}/sha256sum.txt.sig"

          scp "$SSH_OPTS" \
          "${checksum_user}@${checksum_host}:~/${REMOTE_DIR}/checksum/sha256sum.txt.gpg" \
          "${SIGNED_DIR}/sha256sum.txt.gpg"

          # Clean up remote checksum directory
          # shellcheck disable=SC2029,SC2086
          ssh $SSH_OPTS "${checksum_user}@${checksum_host}" "rm -rf ~/${REMOTE_DIR}"

          cd "$CONTENT_DIR"
        done

    - name: compress-artifacts
      image: quay.io/konflux-ci/release-service-utils:82012e03002128f2a226acb23dc5c6fc1c37f5b6
      computeResources:
        limits:
          memory: 256Mi
        requests:
          memory: 256Mi
          cpu: 150m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
      env:
        - name: "SNAPSHOT_JSON"
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -eux

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        CONTENT_DIR=/shared/artifacts

        function compress_component {
          COMPONENT_JSON="$1"
          COMPONENT_NAME=$(jq -r '.name' <<< "$COMPONENT_JSON")
          
          # Per-component directories
          COMPONENT_DIR="$CONTENT_DIR/$COMPONENT_NAME"
          SIGNED_DIR="$COMPONENT_DIR/signed"
          COMPRESSED_DIR="$COMPONENT_DIR/compressed"
          
          mkdir -p "$COMPRESSED_DIR"
          echo "Compressing artifacts for component: $COMPONENT_NAME"

          NUM_MAPPED_FILES=$(jq '.files | length' <<< "${COMPONENT_JSON}")
          UPDATED_FILES="[]"

          for ((i = 0; i < NUM_MAPPED_FILES; i++)) ; do
            FILE=$(jq -c --arg i "$i" '.files[$i|tonumber]' <<< "$COMPONENT_JSON")
            if ! SOURCE=$(jq -er '.source' <<< "$FILE" 2>/dev/null); then
              echo "Missing files.source for component." >&2
              exit 1
            fi
            # Extract just the filename from the source path (remove /releases/ prefix)
            SOURCE_FILENAME=$(basename "$SOURCE")
            DELIVERY_FORMAT=$(jq -r '.delivery_format // ["compressed"] | sort | .[]' <<< "$FILE")

            # Track actual filenames created for this file entry
            ACTUAL_FILES="[]"

            for FORMAT in $DELIVERY_FORMAT; do
              if [ "$FORMAT" = "compressed" ]; then
                case "${SOURCE}" in
                  (*darwin*)
                    # Archive the signed macos binaries (if macos content exists)
                    if [ -d "${SIGNED_DIR}/macos" ]; then
                      tar -czf "${COMPRESSED_DIR}/${SOURCE_FILENAME}" -C "${SIGNED_DIR}" macos
                      # Add file to actual files (filename derived from source)
                      ACTUAL_FILES=$(jq --argjson file "$FILE" '. + [$file]' <<< "$ACTUAL_FILES")
                    else
                      echo "No macos directory found, skipping darwin archive"
                    fi
                    ;;
                  (*linux*)
                    # Archive the linux binaries (if linux content exists)
                    if [ -d "${SIGNED_DIR}/linux" ]; then
                      tar -czf "${COMPRESSED_DIR}/${SOURCE_FILENAME}" -C "${SIGNED_DIR}" linux
                      # Add file to actual files (filename derived from source)
                      ACTUAL_FILES=$(jq --argjson file "$FILE" '. + [$file]' <<< "$ACTUAL_FILES")
                    else
                      echo "No linux directory found, skipping linux archive"
                    fi
                    ;;
                  (*windows*)
                    # Archive the signed windows binaries (if windows content exists)
                    if [ -d "${SIGNED_DIR}/windows" ]; then
                      WINDOWS_FILENAME="${SOURCE_FILENAME%.tar.gz}.zip"
                      (cd "${SIGNED_DIR}" && zip -r "${COMPRESSED_DIR}/${WINDOWS_FILENAME}" windows)
                      # Add file with updated source path (.zip instead of .tar.gz)
                      WINDOWS_SOURCE="${SOURCE%.tar.gz}.zip"
                      ACTUAL_FILES=$(jq --arg src "$WINDOWS_SOURCE" --argjson file "$FILE" \
                        '. + [($file | .source = $src)]' <<< "$ACTUAL_FILES")
                    else
                      echo "No windows directory found, skipping windows archive"
                    fi
                    ;;
                esac
              fi

              # if "raw" is listed in the delivery_mode, copy the specific platform's raw files
              if [ "$FORMAT" = "raw" ]; then
                case "${SOURCE}" in
                  (*darwin*)
                    if [ -d "${SIGNED_DIR}/macos" ]; then
                      find "${SIGNED_DIR}/macos" -type f -exec cp "{}" "${COMPRESSED_DIR}/" \;
                      ACTUAL_FILES=$(jq --argjson file "$FILE" '. + [$file]' <<< "$ACTUAL_FILES")
                    fi
                    ;;
                  (*linux*)
                    if [ -d "${SIGNED_DIR}/linux" ]; then
                      find "${SIGNED_DIR}/linux" -type f -exec cp "{}" "${COMPRESSED_DIR}/" \;
                      ACTUAL_FILES=$(jq --argjson file "$FILE" '. + [$file]' <<< "$ACTUAL_FILES")
                    fi
                    ;;
                  (*windows*)
                    if [ -d "${SIGNED_DIR}/windows" ]; then
                      find "${SIGNED_DIR}/windows" -type f -exec cp "{}" "${COMPRESSED_DIR}/" \;
                      ACTUAL_FILES=$(jq --argjson file "$FILE" '. + [$file]' <<< "$ACTUAL_FILES")
                    fi
                    ;;
                esac
              fi
            done

            # Add all actual files for this original file entry to the updated files list
            UPDATED_FILES=$(jq --argjson actual_files "$ACTUAL_FILES" '. + $actual_files' <<< "$UPDATED_FILES")
          done

          # Copy checksum files to compressed directory
          cp "${SIGNED_DIR}/sha256sum.txt" "${COMPRESSED_DIR}/" 2>/dev/null || true
          cp "${SIGNED_DIR}/sha256sum.txt.sig" "${COMPRESSED_DIR}/" 2>/dev/null || true
          cp "${SIGNED_DIR}/sha256sum.txt.gpg" "${COMPRESSED_DIR}/" 2>/dev/null || true

          # Update the component in SNAPSHOT_JSON with the corrected filenames
          SNAPSHOT_JSON=$(jq --arg name "$COMPONENT_NAME" --argjson updated_files "$UPDATED_FILES" '
            .components |= map(
              if .name == $name then
                .files = $updated_files
              else
                .
              end
            )' <<< "$SNAPSHOT_JSON")
        }

        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")
        for ((c = 0; c < NUM_COMPONENTS; c++)) ; do
            COMPONENT=$(jq -c --arg i "$c" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
            compress_component "$COMPONENT" 2> "$STDERR_FILE"
        done

        # Save the modified snapshot to shared volume so subsequent steps can use it
        echo "$SNAPSHOT_JSON" > /shared/snapshot.json

    - name: push-artifacts
      image: quay.io/konflux-ci/release-service-utils:7072b5b5aa2cc0fc44baf8fb9f8e4a3540fc4fed
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: exodus-gw-secret
          mountPath: /mnt/exodusGwSecret
        - name: pulp-secret
          mountPath: /mnt/pulpSecret
        - name: udcache-secret
          mountPath: /mnt/udcacheSecret
        - name: cgw-secret
          mountPath: /mnt/cgwSecret
      env:
        - name: "SNAPSHOT_JSON"
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -e

        # Check certificate expiration for all certificates used in this step
        echo "=== Checking certificate expiration ==="

        # Check Exodus Gateway certificate
        echo "Checking Exodus Gateway certificate"
        if ! check_cert_expiration "/mnt/exodusGwSecret/cert" "$(params.certExpirationWarnDays)"; then
          echo "ERROR: Exodus Gateway certificate validation failed"
          exit 1
        fi

        # Check Pulp certificate
        echo "Checking Pulp certificate"
        if ! check_cert_expiration "/mnt/pulpSecret/konflux-release-rhsm-pulp.crt" \
            "$(params.certExpirationWarnDays)"; then
          echo "ERROR: Pulp certificate validation failed"
          exit 1
        fi

        # Check UDCache certificate
        echo "Checking UDCache certificate"
        if ! check_cert_expiration "/mnt/udcacheSecret/cert" "$(params.certExpirationWarnDays)"; then
          echo "ERROR: UDCache certificate validation failed"
          exit 1
        fi

        echo "=== All certificates are valid ==="

        # Use the modified snapshot from shared volume if available
        if [ -f /shared/snapshot.json ]; then
          SNAPSHOT_JSON="$(cat /shared/snapshot.json)"
        fi

        EXODUS_CERT="$(cat /mnt/exodusGwSecret/cert)"
        EXODUS_KEY="$(cat /mnt/exodusGwSecret/key)"
        EXODUS_URL="$(cat /mnt/exodusGwSecret/url)"
        PULP_URL="$(cat /mnt/pulpSecret/pulp_url)"
        PULP_CERT="$(cat /mnt/pulpSecret/konflux-release-rhsm-pulp.crt)"
        PULP_KEY="$(cat /mnt/pulpSecret/konflux-release-rhsm-pulp.key)"
        UDC_URL="$(cat /mnt/udcacheSecret/url)"
        UDC_CERT="$(cat /mnt/udcacheSecret/cert)"
        UDC_KEY="$(cat /mnt/udcacheSecret/key)"
        CGW_USERNAME="$(cat /mnt/cgwSecret/username)"
        CGW_PASSWORD="$(cat /mnt/cgwSecret/token)"

        # export the variables used by the scripts in release-service-utils
        export CGW_USERNAME CGW_PASSWORD

        set -x

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                # cleaning up the publishedFiles result to clean up space in the results buffer
                echo > "$(results.publishedFiles.path)"
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        # Setup required variables
        export EXODUS_GW_CERT=/tmp/exodus.crt
        export EXODUS_GW_KEY=/tmp/exodus.key
        EXODUS_CONF_PATH=/tmp/exodus-rsync.conf
        export PULP_CERT_FILE=/tmp/pulp.crt
        export PULP_KEY_FILE=/tmp/pulp.key
        export UDCACHE_CERT=/tmp/udc.crt
        export UDCACHE_KEY=/tmp/udc.key
        EXODUS_GW_ENV=$(params.exodusGwEnv)
        export EXODUS_GW_ENV
        export EXODUS_GW_URL="$EXODUS_URL"
        export EXODUS_PULP_HOOK_ENABLED=True
        export EXODUS_GW_TIMEOUT=7200

        set +x
        echo "$EXODUS_CERT" > "$EXODUS_GW_CERT"
        echo "$EXODUS_KEY" > "$EXODUS_GW_KEY"
        echo "$PULP_CERT" > "$PULP_CERT_FILE"
        echo "$PULP_KEY" > "$PULP_KEY_FILE"
        echo "$UDC_CERT" > "$UDCACHE_CERT"
        echo "$UDC_KEY" > "$UDCACHE_KEY"
        set -x

        CONTENT_DIR="/shared/artifacts"

        # save the results - list all files from all component compressed directories
        find "${CONTENT_DIR}"/*/compressed -type f -exec basename {} \; 2>/dev/null \
          | tail -c 512 | tee "$(results.publishedFiles.path)"

        create_exodus_conf() {
          echo "Creating Exodus configuration file....."
          set +x
          cat >"$EXODUS_CONF_PATH" <<EOF
        gwcert:   $EXODUS_GW_CERT
        gwkey:    $EXODUS_GW_KEY
        gwurl:    $EXODUS_GW_URL
        gwenv:    $EXODUS_GW_ENV

        logger: file:/proc/1/fd/1
        loglevel: info

        environments:
          - prefix: exodus
        EOF
          set -x
        }

        push_component_to_pulp() {
          local component_name=$1
          local component_dir="${CONTENT_DIR}/${component_name}/compressed"
          
          # Get version and destination from the component's staged config
          version=$(jq -cr --arg name "$component_name" '
            .components[] | select(.name == $name) | .staged.version // ""
          ' <<< "$SNAPSHOT_JSON")
          
          staged_destination=$(jq -cr --arg name "$component_name" '
            .components[] | select(.name == $name) | .staged.destination // ""
          ' <<< "$SNAPSHOT_JSON")
          
          if [[ -z "$version" || -z "$staged_destination" ]]; then
            echo "Error: Pulp push requires both staged.version and staged.destination" \
              "for component $component_name" >&2
            exit 1
          fi

          echo "Pushing component $component_name to customer portal with pulp"
          cd "$component_dir"
          
          staged_json='{"header":{"version": "0.2"},"payload":{"files":[]}}'
          # shellcheck disable=SC2035
          while IFS= read -r -d '' file ; do
              staged_json=$(jq --arg filename "$(basename "$file")" --arg path "$file" \
                --arg version "$version" \
                '.payload.files[.payload.files | length] =
                {"filename": $filename, "relative_path": $path, "version": $version}' <<< "$staged_json")
          done < <(find * -type f -print0)
          echo "$staged_json" | yq -P -I 4 > staged.yaml

          pulp_push_wrapper --debug --source "$component_dir" --pulp-url "$PULP_URL" \
            --pulp-cert $PULP_CERT_FILE --pulp-key $PULP_KEY_FILE --udcache-url "$UDC_URL"

          rm -f staged.yaml
          cd "$CONTENT_DIR"
        }

        push_component_to_cdn() {
          local component_name=$1
          local component_dir="${CONTENT_DIR}/${component_name}/compressed"
          
          echo "Pushing component $component_name to CDN with exodus-rsync"
          create_exodus_conf
          prefix="exodus:/content/origin/files/sha256"
          
          cd "$component_dir"
          # shellcheck disable=SC2035
          while IFS= read -r -d '' file; do
            set +x
            file_name=$(basename "$file")
            checksum=$(sha256sum "$file" | awk '{print $1}')
            destination_path="$prefix/${checksum:0:2}/$checksum/$file_name"
            set -x

            rsync --exodus-conf "$EXODUS_CONF_PATH" "$file" "$destination_path"
          done < <(find * -type f -print0)
          cd "$CONTENT_DIR"
        }

        publish_component_to_cgw() {
          local component_name=$1
          local component_dir="${CONTENT_DIR}/${component_name}/compressed"
          
          # Update contentDir for this component in SNAPSHOT_JSON
          SNAPSHOT_JSON=$(
            jq --arg name "$component_name" --arg dir "$component_dir" '
              .components |= map(
                if .name == $name and .contentGateway? then
                  .contentGateway.contentDir = $dir
                else
                  .
                end
              )
            ' <<<"$SNAPSHOT_JSON"
          )
        }

        # Process each component
        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")
        for ((c = 0; c < NUM_COMPONENTS; c++)); do
          COMPONENT=$(jq -c --arg i "$c" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
          COMPONENT_NAME=$(jq -r '.name' <<< "$COMPONENT")
          
          HAS_STAGED=$(jq -r '.staged | length > 0' <<< "$COMPONENT")
          HAS_CGW=$(jq -r '.contentGateway | length > 0' <<< "$COMPONENT")

          echo "Processing component: $COMPONENT_NAME (staged=$HAS_STAGED, cgw=$HAS_CGW)"

          if [[ "$HAS_STAGED" == "true" ]]; then
            # Push to customer portal (pulp) - CDN push not needed when using pulp
            push_component_to_pulp "$COMPONENT_NAME" 2> "$STDERR_FILE"
          elif [[ "$HAS_CGW" == "true" ]]; then
            # Only push to CDN when NOT pushing to pulp
            push_component_to_cdn "$COMPONENT_NAME" > >(tee "$STDERR_FILE") 2>&1 || true
          fi
          
          if [[ "$HAS_CGW" == "true" ]]; then
            publish_component_to_cgw "$COMPONENT_NAME"
          fi
        done

        # Final CGW publish with all components' contentDir set
        CGW_PUSH=$(jq 'any(.components[]?.contentGateway?; length > 0)' <<< "$SNAPSHOT_JSON")
        if [[ "$CGW_PUSH" == "true" ]]; then
          echo "Publishing all components to CGW..."
          publish_to_cgw_wrapper \
            --cgw_host "$(params.cgwHostname)" \
            --data_json "$SNAPSHOT_JSON" 2> >(tee "$STDERR_FILE" >&2)
        fi
