---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: push-artifacts-to-cdn-task
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: |-
    Tekton task to push artifacts to the Customer Portal using Pulp and optionally to
    the Developer Portal using exodus-rsync with optional signing. It uses logic based
    on the snapshot data to determine which targets to publish to: if components contain
    both `staged` and `contentGateway` data, artifacts are pushed to the Customer Portal
    (Pulp) and to CGW; if components contain `staged` data only, artifacts are
    pushed to the Customer Portal (Pulp); if components contain `contentGateway`
    data only, artifacts are pushed to the Developer Portal (exodus-rsync) and CGW.
  params:
    - name: snapshot_json
      type: string
      description: String containing a JSON representation of the snapshot spec
    - name: concurrentLimit
      type: string
      description: The maximum number of images to be pulled at once
      default: 3
    # signing params start here
    - name: author
      type: string
      description: Author taken from Release to be used for checksum signing
    - name: signingKeyName
      type: string
      description: Signing key name to be used for checksum signing
    - name: quayURL
      type: string
      description: Quay URL of the repo where content will be shared between tasks
      default: quay.io/konflux-artifacts
    - name: quaySecret
      type: string
      description: Secret to interact with Quay
      default: quay-credentials
    - name: windowsCredentials
      type: string
      description: Secret to interact with the Windows signing host
      default: windows-credentials
    - name: windowsSSHKey
      type: string
      description: Secret containing SSH private key for the Windows signing host
      default: windows-ssh-key
    - name: macHostCredentials
      type: string
      description: Secret to interact with the Mac signing host
      default: mac-host-credentials
    - name: macSigningCredentials
      type: string
      description: Secret to interact with the Mac signing utils
      default: mac-signing-credentials
    - name: macSSHKey
      type: string
      description: Secret containing SSH private key for the Mac signing host
      default: mac-ssh-key
    - name: checksumUser
      type: string
      description: User to interact with the checksum host
      default: konflux-release-signing-sa
    - name: checksumHost
      type: string
      description: Hostname of the checksum host
      default: etera-worker.hosted.upshift.rdu2.redhat.com
    - name: checksumFingerprint
      type: string
      description: Secret containing the fingerprint for the checksum host
      default: checksum-fingerprint
    - name: checksumKeytab
      type: string
      description: Secret containing the keytab for the checksum host
      default: checksum-keytab
    - name: kerberosRealm
      type: string
      description: Kerberos realm for the checksum host
      default: IPA.REDHAT.COM
    # cdn params start here
    - name: exodusGwSecret
      type: string
      description: Env specific secret containing the Exodus Gateway configs
    - name: exodusGwEnv
      type: string
      description: Environment to use in the Exodus Gateway. Options are [live, pre]
    - name: pulpSecret
      type: string
      description: Env specific secret containing the rhsm-pulp credentials
    - name: udcacheSecret
      type: string
      description: Env specific secret containing the udcache credentials
    - name: cgwHostname
      type: string
      description: Env specific hostname for content gateway
    - name: cgwSecret
      type: string
      description: Env specific secret containing the content gateway credentials
  results:
    - name: result
      description: Success if the task succeeds, the error otherwise
    - name: signedMacDigest
      description: Digest for signed Mac files
    - name: unsignedMacDigest
      description: Digest for unsigned Mac files
    - name: signedWindowsDigest
      description: Digest from signed Windows files
    - name: unsignedWindowsDigest
      description: Digest from unsigned Windows files
    - name: publishedFiles
      description: List of published files
  volumes:
    - name: shared-dir
      emptyDir: {}
    - name: mac-ssh-key-vol
      secret:
        secretName: mac-ssh-key
        defaultMode: 0400
    - name: windows-ssh-key-vol
      secret:
        secretName: windows-ssh-key
        defaultMode: 0400
    - name: checksum-fingerprint-vol
      secret:
        secretName: checksum-fingerprint
        defaultMode: 0400
    - name: checksum-keytab-vol
      secret:
        secretName: checksum-keytab
        defaultMode: 0400
    - name: redhat-workloads-token
      secret:
        secretName: redhat-workloads-token
        defaultMode: 0400
    - name: quay-secret
      secret:
        secretName: $(params.quaySecret)
        defaultMode: 0400
    - name: mac-host-credentials
      secret:
        secretName: $(params.macHostCredentials)
        defaultMode: 0400
    - name: mac-signing-credentials
      secret:
        secretName: $(params.macSigningCredentials)
        defaultMode: 0400
    - name: windows-credentials
      secret:
        secretName: $(params.windowsCredentials)
        defaultMode: 0400
    - name: exodus-gw-secret
      secret:
        secretName: $(params.exodusGwSecret)
        defaultMode: 0400
    - name: pulp-secret
      secret:
        secretName: $(params.pulpSecret)
        defaultMode: 0400
    - name: udcache-secret
      secret:
        secretName: $(params.udcacheSecret)
        defaultMode: 0400
    - name: cgw-secret
      secret:
        secretName: $(params.cgwSecret)
        defaultMode: 0400
  steps:
    - name: extract-artifacts
      image: quay.io/konflux-ci/release-service-utils:de01eb742f1fabeaefd1aabce1b24061b3fe72e1
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: redhat-workloads-token
          mountPath: /mnt/redhat-workloads-token
      env:
        - name: "SNAPSHOT_JSON"
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -e

        DOCKER_CONFIG_JSON="$(cat /mnt/redhat-workloads-token/.dockerconfigjson)"

        set -x

        STDERR_FILE=/tmp/stderr.txt

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        mkdir -p ~/.docker
        set +x
        # Quotes are added to the secret so it applies in k8s nicely. But now we have to remove them
        echo "$DOCKER_CONFIG_JSON" | sed -r 's/(^|\})[^{}]+(\{|$)/\1\2/g' > ~/.docker/config.json
        set -x

        DISK_IMAGE_DIR="/shared/artifacts"
        export DISK_IMAGE_DIR
        mkdir -p "$DISK_IMAGE_DIR"

        process_component() { # Expected argument is [component json]
            COMPONENT=$1
            PULLSPEC=$(jq -er '.containerImage' <<< "${COMPONENT}") \
                  || (echo "Missing containerImage for component." >&2 && exit 1 )

            STAGED_DESTINATION=$(jq -r '.staged.destination // empty' <<< "${COMPONENT}")

            if [ -z "$STAGED_DESTINATION" ]; then
              # Use a default destination if not provided
              DESTINATION="${DISK_IMAGE_DIR}/default/FILES"
              echo "No staged.destination specified for component; using default destination: $DESTINATION"
            else
              DESTINATION="${DISK_IMAGE_DIR}/${STAGED_DESTINATION}/FILES"
            fi

            mkdir -p "${DESTINATION}"

            # Extract binaries from container image using skopeo (like extract-binaries-from-image task)
            TMP_DIR=$(mktemp -d)

            # Create auth file for skopeo
            AUTH_FILE=$(mktemp)
            select-oci-auth "${PULLSPEC}" > "$AUTH_FILE"

            # Use skopeo to copy container manifest and layers
            skopeo copy --retry-times 3 --authfile "$AUTH_FILE" docker://"$PULLSPEC" dir:"$TMP_DIR"

            cd "$TMP_DIR"

            # Determine which directories to extract from source paths in files or staged.files
            EXTRACT_DIRS=()

            # Check .files[].source paths
            NUM_FILES=$(jq '.files | length // 0' <<< "${COMPONENT}")
            for ((i = 0; i < NUM_FILES; i++)); do
                SOURCE_PATH=$(jq -r --arg i "$i" '.files[$i|tonumber].source // empty' <<< "${COMPONENT}")
                if [ -n "$SOURCE_PATH" ]; then
                    # Extract directory part (e.g., "/releases/file.gz" -> "releases")
                    DIR_PATH=$(dirname "$SOURCE_PATH" | sed 's|^/||')
                    if [ "$DIR_PATH" != "." ] && [ -n "$DIR_PATH" ]; then
                        EXTRACT_DIRS+=("$DIR_PATH")
                    fi
                fi
            done

            # Check .staged.files[].source paths
            NUM_STAGED_FILES=$(jq '.staged.files | length // 0' <<< "${COMPONENT}")
            for ((i = 0; i < NUM_STAGED_FILES; i++)); do
                SOURCE_PATH=$(jq -r --arg i "$i" '.staged.files[$i|tonumber].source // empty' <<< "${COMPONENT}")
                if [ -n "$SOURCE_PATH" ]; then
                    # Extract directory part (e.g., "/releases/file.gz" -> "releases")
                    DIR_PATH=$(dirname "$SOURCE_PATH" | sed 's|^/||')
                    if [ "$DIR_PATH" != "." ] && [ -n "$DIR_PATH" ]; then
                        EXTRACT_DIRS+=("$DIR_PATH")
                    fi
                fi
            done

            # Default to "releases" if no source directories found
            if [ ${#EXTRACT_DIRS[@]} -eq 0 ]; then
                EXTRACT_DIRS=("releases")
            fi

            # Remove duplicates and extract each unique directory
            mapfile -t UNIQUE_DIRS < <(printf "%s\n" "${EXTRACT_DIRS[@]}" | sort -u)

            for IMAGE_PATH in "${UNIQUE_DIRS[@]}"; do
                echo "Looking for directory: $IMAGE_PATH"
                for DIGEST in $(jq -r ".layers[].digest" manifest.json); do
                    FILE=${DIGEST#sha256:}
                    # Check if the archive contains the target dir
                    if tar -tf "$FILE" | grep -q "^$IMAGE_PATH/"; then
                        echo "Extracting $IMAGE_PATH/ from $FILE..."
                        tar -xzvf "$FILE" "$IMAGE_PATH"
                    else
                        echo "skipping $FILE. It doesn't contain the $IMAGE_PATH dir"
                    fi
                done

                # Copy extracted files directly to destination (flattened like extract-binaries-from-image)
                if [ -d "$IMAGE_PATH" ]; then
                    cp "$IMAGE_PATH"/* "$DESTINATION"/ 2>/dev/null || echo "No files found in $IMAGE_PATH directory"
                fi
            done

            # Clean up temporary directory
            rm -rf "$TMP_DIR"

        }

        RUNNING_JOBS="\j" # Bash parameter for number of jobs currently running
        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")

        # Pull each component in parallel
        for ((i = 0; i < NUM_COMPONENTS; i++)) ; do
            COMPONENT=$(jq -c --arg i "$i" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
            # Limit batch size to concurrent limit
            while (( ${RUNNING_JOBS@P} >= $(params.concurrentLimit) )); do
                wait -n
            done
            process_component "$COMPONENT" 2> "$STDERR_FILE" &
        done

        # Wait for remaining processes to finish
        while (( ${RUNNING_JOBS@P} > 0 )); do
            wait -n
        done
    - name: push-unsigned-using-oras
      image: quay.io/konflux-ci/release-service-utils:de01eb742f1fabeaefd1aabce1b24061b3fe72e1
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: quay-secret
          mountPath: /mnt/quaySecret
      script: |
        #!/usr/bin/env bash
        set -eu

        QUAY_USER="$(cat "/mnt/quaySecret/username")"
        QUAY_PASS="$(cat "/mnt/quaySecret/password")"

        set -x

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        CONTENT_DIR=/shared/artifacts
        find $CONTENT_DIR
        UNSIGNED_DIR=$CONTENT_DIR/unsigned
        MAC_CONTENT=$UNSIGNED_DIR/macos
        WINDOWS_CONTENT=$UNSIGNED_DIR/windows
        LINUX_CONTENT=$CONTENT_DIR/linux

        mkdir -p "$MAC_CONTENT" "$WINDOWS_CONTENT" "$LINUX_CONTENT"
        cd "$CONTENT_DIR"

        # First unpack all archives in place (removing the archives)
        find "$CONTENT_DIR" -type f -iregex ".*\.zip\|.*\.gz" 2>/dev/null | while read -r file; do
          dir=$(dirname "$file")
          case "$file" in
            (*.tar.gz)
              tar -xzf "$file" -C "$dir" && rm "$file"
              ;;
            (*.gz)
              gzip -d "$file"
              ;;
            (*.zip)
              unzip "$file" -d "$dir" && rm "$file"
              ;;
          esac
        done

        # Then move unpacked files to appropriate directories based on architecture
        find "$CONTENT_DIR" -type f 2>/dev/null | while read -r file; do
          case "$file" in
            (*darwin*)
              mv "$file" unsigned/macos/
              ;;
            (*windows*)
              mv "$file" unsigned/windows/
              ;;
            (*linux*)
              mv "$file" linux/
              ;;
          esac
        done

        cd "$UNSIGNED_DIR"

        echo "Logging into Quay..."
        set +x
        oras login quay.io -u "${QUAY_USER}" -p "${QUAY_PASS}" > /dev/null 2>&1
        set -x
        echo "Pushing unsigned Macos content to $(params.quayURL)..."
        output=$(oras push "$(params.quayURL)/unsigned" macos)
        mac_digest=$(echo "$output" | grep 'Digest:' | awk '{print $2}')
        echo "Digest for mac content: $mac_digest"
        echo -n "$mac_digest" > "$(results.unsignedMacDigest.path)"

        echo "Pushing unsigned Windows content to $(params.quayURL)..."
        output=$(oras push "$(params.quayURL)/unsigned" windows)
        windows_digest=$(echo "$output" | grep 'Digest:' | awk '{print $2}')
        echo "Digest for windows content: $windows_digest"
        echo -n "$windows_digest" > "$(results.unsignedWindowsDigest.path)"
    - name: sign-mac-binaries
      image: quay.io/konflux-ci/release-service-utils:de01eb742f1fabeaefd1aabce1b24061b3fe72e1
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: mac-ssh-key-vol
          mountPath: "/mnt/secrets"
        - name: quay-secret
          mountPath: /mnt/quaySecret
        - name: mac-host-credentials
          mountPath: /mnt/macHostCredentials
        - name: mac-signing-credentials
          mountPath: /mnt/macSigningCredentials
      env:
        - name: QUAY_URL
          value: $(params.quayURL)
        - name: PIPELINE_UID
          value: $(context.taskRun.uid)
      script: |
        #!/usr/bin/env bash
        set -eu

        MAC_USER="$(cat /mnt/macHostCredentials/username)"
        MAC_HOST="$(cat /mnt/macHostCredentials/host)"
        KEYCHAIN_PASSWORD="$(cat /mnt/macSigningCredentials/keychain_password)"
        SIGNING_IDENTITY="$(cat /mnt/macSigningCredentials/signing_identity)"
        APPLE_ID="$(cat /mnt/macSigningCredentials/apple_id)"
        TEAM_ID="$(cat /mnt/macSigningCredentials/team_id)"
        APP_SPECIFIC_PASSWORD="$(cat /mnt/macSigningCredentials/app_specific_password)"
        QUAY_USER="$(cat /mnt/quaySecret/username)"
        QUAY_PASS="$(cat /mnt/quaySecret/password)"

        set -x

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        mkdir -p /tmp/.ssh
        chmod 700 /tmp/.ssh
        cp "/mnt/secrets/mac_id_rsa" /tmp/.ssh/id_rsa
        cp "/mnt/secrets/mac_fingerprint" /tmp/.ssh/known_hosts
        chmod 600 /tmp/.ssh/id_rsa /tmp/.ssh/known_hosts

        SSH_OPTS=(-i /tmp/.ssh/id_rsa -o UserKnownHostsFile=/tmp/.ssh/known_hosts -o IdentitiesOnly=yes)

        # shell check complains about the variable (unsigned_digest) not being used but it is used in the script
        # shellcheck disable=SC2034
        unsigned_digest=$(cat "$(results.unsignedMacDigest.path)")
        mac_signing_script="/tmp/mac_signing_script.sh"

        TEMP_DIR="/tmp/$(context.taskRun.uid)"
        BINARY_PATH="$TEMP_DIR/unsigned/macos"
        ZIP_PATH="$TEMP_DIR/signed_content.zip"
        DIGEST_FILE="$TEMP_DIR/push_digest.txt"

        cat << EOF > "$mac_signing_script"
        #!/bin/bash
        set -eux

        mkdir -p "$TEMP_DIR"
        mkdir -p "$BINARY_PATH"

        cd "$TEMP_DIR"
        set +x
        /usr/local/bin/oras login quay.io -u ${QUAY_USER} -p ${QUAY_PASS}
        set -x
        /usr/local/bin/oras pull $(params.quayURL)/unsigned@$unsigned_digest -o "$BINARY_PATH"
        # This is the directory where the content was extracted
        CONTENT_DIR=\$(find "$BINARY_PATH" -maxdepth 1 -type d | tail -n 1)

        set +x
        security unlock-keychain -p $KEYCHAIN_PASSWORD login.keychain
        set -x
        echo "Signing files in the \$CONTENT_DIR directory..."
        find "\$CONTENT_DIR" -type f | while read file; do
            echo "Signing: \$file"
            if ! xcrun codesign --sign "Developer ID Application: $SIGNING_IDENTITY" \
                --options runtime --timestamp --force "\$file"; then
                echo "Failed to sign file: \$file"
                exit 1
            fi
        done

        cd "$BINARY_PATH"
        NEW_CONTENT_DIR=\$(basename "\$CONTENT_DIR")
        zip -r "$ZIP_PATH" "\$NEW_CONTENT_DIR"

        echo "Submitting ZIP file to Apple notary service..."
        set +x
        xcrun notarytool submit "$ZIP_PATH" \
            --wait \
            --apple-id "$APPLE_ID" \
            --team-id "$TEAM_ID" \
            --password "$APP_SPECIFIC_PASSWORD"
        set -x

        PUSH_OUTPUT=\$(/usr/local/bin/oras push "$QUAY_URL/signed:$(context.taskRun.uid)-mac" "\$NEW_CONTENT_DIR")
        SIGNED_DIGEST=\$(echo "\$PUSH_OUTPUT" | grep 'Digest:' | awk '{print \$2}')
        echo -n "\$SIGNED_DIGEST" >> "$DIGEST_FILE"
        echo "Process completed successfully."
        EOF

        # Copy the script to the Mac host
        scp "${SSH_OPTS[@]}" "$mac_signing_script" "${MAC_USER}@${MAC_HOST}:/tmp/mac_signing_script.sh"

        # Execute the script on the Mac host
        ssh "${SSH_OPTS[@]}" "${MAC_USER}@${MAC_HOST}" bash /tmp/mac_signing_script.sh

        # Copy the signed digest back to the pipeline
        scp "${SSH_OPTS[@]}" "${MAC_USER}@${MAC_HOST}:/tmp/$(context.taskRun.uid)/push_digest.txt" \
            "$(results.signedMacDigest.path)"

        # Clean up the Mac host now that we are done
        # shell check complains about the variable $(context.taskRun.uid) being evaluated on the client side
        # shellcheck disable=SC2029
        ssh "${SSH_OPTS[@]}" "${MAC_USER}@${MAC_HOST}" "rm -rf /tmp/$(context.taskRun.uid)"
    - name: sign-windows-binaries
      image: quay.io/konflux-ci/release-service-utils:de01eb742f1fabeaefd1aabce1b24061b3fe72e1
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: windows-ssh-key-vol
          mountPath: /mnt/secrets
        - name: quay-secret
          mountPath: /mnt/quaySecret
        - name: windows-credentials
          mountPath: /mnt/windowsCredentials
      script: |
        #!/usr/bin/env bash
        set -eu

        WINDOWS_USER="$(cat /mnt/windowsCredentials/username)"
        WINDOWS_PORT="$(cat /mnt/windowsCredentials/port)"
        WINDOWS_HOST="$(cat /mnt/windowsCredentials/host)"
        QUAY_USER="$(cat /mnt/quaySecret/username)"
        QUAY_PASS="$(cat /mnt/quaySecret/password)"

        set -x

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        mkdir -p /tmp/.ssh
        chmod 700 /tmp/.ssh
        cp "/mnt/secrets/windows_id_rsa" /tmp/.ssh/id_rsa
        cp "/mnt/secrets/windows_fingerprint" /tmp/.ssh/known_hosts
        chmod 600 /tmp/.ssh/known_hosts /tmp/.ssh/id_rsa

        SSH_OPTS=(-i /tmp/.ssh/id_rsa -o UserKnownHostsFile=/tmp/.ssh/known_hosts \
          -o IdentitiesOnly=yes -p "${WINDOWS_PORT}")
        SCP_OPTS=(-i /tmp/.ssh/id_rsa -o UserKnownHostsFile=/tmp/.ssh/known_hosts \
          -o IdentitiesOnly=yes -P "${WINDOWS_PORT}")

        unsigned_digest=$(cat "$(results.unsignedWindowsDigest.path)")
        # Create the batch script
        windows_signing_script_file="/tmp/windows_signing_script_file.bat"
        set +x
        cat << EOF > "$windows_signing_script_file"

        mkdir %TEMP%\$(context.taskRun.uid) && cd /d %TEMP%\$(context.taskRun.uid)
        @echo off
        oras login quay.io -u ${QUAY_USER} -p ${QUAY_PASS}
        @echo on
        oras pull $(params.quayURL)/unsigned@${unsigned_digest}

        signtool sign /v /n "Red Hat" /fd SHA256 /tr http://timestamp.digicert.com /td SHA256 ^
        %TEMP%\$(context.taskRun.uid)\windows\*

        if errorlevel 1 (
          echo Signing of binaries failed
          exit /B %ERRORLEVEL%
        )

        signtool verify /v /pa %TEMP%\$(context.taskRun.uid)\windows\*

        if errorlevel 1 (
          echo Verification of binaries failed
          exit /B %ERRORLEVEL%
        )

        echo [%DATE% %TIME%] Signing of Windows binaries completed successfully

        oras push $(params.quayURL)/signed:$(context.taskRun.uid)-windows windows \
        > oras_push_output.txt 2>&1

        for /f "tokens=2,3 delims=: " %%a in ('findstr "Digest:" oras_push_output.txt') do @echo %%a:%%b > digest.txt
        EOF
        set -x
        # shellcheck disable=SC2086
        scp "${SCP_OPTS[@]}" "$windows_signing_script_file" \
        "${WINDOWS_USER}@${WINDOWS_HOST}:C:/Users/${WINDOWS_USER}/AppData/Local/Temp/windows_signing_script_file.bat"

        # Execute the script on the Windows host
        # shellcheck disable=SC2029,SC2086
        ssh "${SSH_OPTS[@]}" "${WINDOWS_USER}@${WINDOWS_HOST}" \
          "C:/Users/${WINDOWS_USER}/AppData/Local/Temp/windows_signing_script_file.bat"

        # disable shellcheck for escaping the taskRun.uid as we want that evaluated on client side
        # shellcheck disable=SC2029,SC2086
        scp "${SCP_OPTS[@]}" "${WINDOWS_USER}@${WINDOWS_HOST}:\
        C:/Users/${WINDOWS_USER}/AppData/Local/Temp/$(context.taskRun.uid)/digest.txt" \
        "$(results.signedWindowsDigest.path)"

        # Remove trailing spaces, carriage returns, newlines
        sed -i 's/[[:space:]]*$//; s/\r//g; :a;N;$!ba;s/\n//g' "$(results.signedWindowsDigest.path)"

        # Clean up the windows host now that we are done
        # disable shellcheck for escaping the taskRun.uid as we want that evaluated on client side
        # shellcheck disable=SC2029,SC2086
        ssh "${SSH_OPTS[@]}" "${WINDOWS_USER}@${WINDOWS_HOST}" "Remove-Item -LiteralPath \
        C:\\Users\\${WINDOWS_USER}\\AppData\\Local\\Temp\\$(context.taskRun.uid) -Force -Recurse"
    - name: generate-checksums
      image: quay.io/konflux-ci/release-service-utils:de01eb742f1fabeaefd1aabce1b24061b3fe72e1
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: checksum-fingerprint-vol
          mountPath: /mnt/secrets_fingerprint
        - name: checksum-keytab-vol
          mountPath: /mnt/secrets_keytab
        - name: quay-secret
          mountPath: /mnt/quaySecret
      env:
        - name: AUTHOR
          value: $(params.author)
        - name: SIGNING_KEY_NAME
          value: $(params.signingKeyName)
      script: |
        #!/usr/bin/env bash
        set -eu

        QUAY_USER="$(cat /mnt/quaySecret/username)"
        QUAY_PASS="$(cat /mnt/quaySecret/password)"

        set -x

        #---------------------------------------------------------------------------------------
        # This step generates checksums for all of the binaries in the content directory and
        # signs them using the checksum host.
        # The general workflow is that the binaries are extracted from the image(previous task),
        # signed on remote hosts (windows and mac) and then a sha256sum is generated for each
        # binary. The shasums are collected in a sha256sum.txt file which is then transferred to
        # the checksum host for signing with Red Hat's GPG key.
        # The detached signatures are returned to the workspace for inclusion in the later tasks
        # to be pushed to CDN and the Red Hat Developer Portal.
        #---------------------------------------------------------------------------------------

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        if [[ ${AUTHOR} == "" ]] ; then
          echo Error: invalid author
          exit 1
        fi

        SSH_OPTS="-o UserKnownHostsFile=/tmp/.ssh/known_hosts \
                    -o GSSAPIAuthentication=yes \
                    -o GSSAPIDelegateCredentials=yes \
                    -o IdentitiesOnly=yes"

        sign_file() {
            sign_method=$1  # The signing method: --clearsign or --gpgsign
            checksum_user=$(params.checksumUser)
            checksum_host=$(params.checksumHost)
            pipeline_run_uid=$(context.taskRun.uid)
            output_path="/home/$checksum_user/$pipeline_run_uid/checksum/sha256sum.txt.$2"
            input_file="/home/$checksum_user/$pipeline_run_uid/checksum/sha256sum.txt"

            echo "Executing SSH command with sign method: $sign_method"
            # shellcheck disable=SC2029,SC2086
            ssh $SSH_OPTS "$checksum_user@$checksum_host" \
            "rpm-sign --nat $sign_method --key $SIGNING_KEY_NAME --onbehalfof=$AUTHOR \
            --output $output_path $input_file"
        }

        # Generate a kerberos ticket to ssh to the checksum host.
        # The ticket is required for interacting with rpm-sign as well,
        # so we use GSSAPI Delegate (in ssh opts) to transfer the ticket to the checksum host
        KRB5CCNAME=FILE:/tmp/krb5cc_$(id -u)
        export KRB5CCNAME
        base64 -d /mnt/secrets_keytab/keytab > /tmp/sa.keytab
        retry 5 kinit -kt /tmp/sa.keytab "$(params.checksumUser)@$(params.kerberosRealm)"

        mkdir -p /tmp/.ssh
        chmod 700 /tmp/.ssh
        cp "/mnt/secrets_fingerprint/fingerprint" /tmp/.ssh/known_hosts
        chmod 600 /tmp/.ssh/known_hosts

        # get all of the signed binaries into a common directory
        CONTENT_DIR=/shared/artifacts
        SIGNED_DIR="$CONTENT_DIR/signed"
        mkdir -p "$SIGNED_DIR"
        mkdir -p "$CONTENT_DIR"/linux
        cp -r "$CONTENT_DIR"/linux/* "$SIGNED_DIR"
        cd "$SIGNED_DIR"
        set +x
        oras login quay.io -u "$QUAY_USER" -p "$QUAY_PASS"
        set -x
        signed_mac_digest=$(cat "$(results.signedMacDigest.path)")
        signed_windows_digest=$(cat "$(results.signedWindowsDigest.path)")
        signed_windows_digest=${signed_windows_digest//[[:space:]]/}
        # shellcheck disable=SC2086,SC2046
        oras pull $(params.quayURL)/signed@${signed_mac_digest}
        # shellcheck disable=SC2086,SC2046
        oras pull $(params.quayURL)/signed@${signed_windows_digest}

        # Copy everything to SIGNED_DIR and remove mac,windows dirs
        cp macos/* .
        cp windows/* .
        rm -r macos/ windows/

        # generate checksums for all of the binaries
        SHA_SUM_PATH="${CONTENT_DIR}/sha256sum.txt"
        touch "$SHA_SUM_PATH"
        for file in *; do
            if [ -f "$file" ]; then
                checksum=$(sha256sum "$file" | awk '{ print $1 }')
                echo "$checksum  $file" >> "$SHA_SUM_PATH"
            fi
        done
        # Send sha256sum.txt to the checksum host for signing
        # shellcheck disable=SC2029,SC2086
        ssh $SSH_OPTS "$(params.checksumUser)@$(params.checksumHost)" "mkdir -p ~/$(context.taskRun.uid)/checksum"
        # shellcheck disable=SC2086
        scp $SSH_OPTS "${SHA_SUM_PATH}" \
        "$(params.checksumUser)@$(params.checksumHost):~/$(context.taskRun.uid)/checksum"

        sign_file --clearsign sig
        sign_file --gpgsign gpg

        # scp the two files back to the content directory
        scp "$SSH_OPTS" \
        "$(params.checksumUser)@$(params.checksumHost):~/$(context.taskRun.uid)/checksum/sha256sum.txt.sig" \
        "${SIGNED_DIR}/sha256sum.txt.sig"

        scp "$SSH_OPTS" \
        "$(params.checksumUser)@$(params.checksumHost):~/$(context.taskRun.uid)/checksum/sha256sum.txt.gpg" \
        "${SIGNED_DIR}/sha256sum.txt.gpg"

        mv "$SHA_SUM_PATH" "${SIGNED_DIR}/sha256sum.txt"

    - name: compress-artifacts
      image: quay.io/konflux-ci/release-service-utils:de01eb742f1fabeaefd1aabce1b24061b3fe72e1
      computeResources:
        limits:
          memory: 256Mi
        requests:
          memory: 256Mi
          cpu: 150m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
      env:
        - name: "SNAPSHOT_JSON"
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -eux

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        CONTENT_DIR=/shared/artifacts
        COMPRESSED_DIR="$CONTENT_DIR/compressed"

        function compress_components {
          mkdir -p "$COMPRESSED_DIR"
          COMPONENT_JSON="$1"
          NUM_MAPPED_FILES=$(jq '.files | length' <<< "${COMPONENT_JSON}")
          for ((i = 0; i < NUM_MAPPED_FILES; i++)) ; do
            FILE=$(jq -c --arg i "$i" '.files[$i|tonumber]' <<< "$COMPONENT")
            if ! SOURCE=$(jq -er '.source' <<< "$FILE" 2>/dev/null); then
              echo "Missing files.source for component." >&2
              exit 1
            fi
            # Extract just the filename from the source path (remove /releases/ prefix)
            SOURCE_FILENAME=$(basename "$SOURCE")
            DELIVERY_FORMAT=$(jq -r '.delivery_format // ["compressed"] | sort | .[]' <<< "$FILE")
            for FORMAT in $DELIVERY_FORMAT; do
              if [ "$FORMAT" = "compressed" ]; then
                case "${SOURCE}" in
                  (*darwin*)
                    # Archive the extracted macos binaries
                    tar -czf "${COMPRESSED_DIR}/${SOURCE_FILENAME}" -C "${CONTENT_DIR}" unsigned/macos
                    ;;
                  (*linux*)
                    # Archive the extracted linux binaries
                    tar -czf "${COMPRESSED_DIR}/${SOURCE_FILENAME}" -C "${CONTENT_DIR}" linux
                    ;;
                  (*windows*)
                    # Archive the extracted windows binaries (zip doesn't have -C, so use full path)
                    (cd "${CONTENT_DIR}" && zip -r "${COMPRESSED_DIR}/${SOURCE_FILENAME%.tar.gz}.zip" unsigned/windows)
                    ;;
                esac
              fi

              # if "raw" is listed in the delivery_mode, make sure the binaries will be also pushed
              if [ "$FORMAT" = "raw" ]; then
                find "${CONTENT_DIR}/unsigned" "${CONTENT_DIR}/linux" -type f -exec cp "{}" "${COMPRESSED_DIR}/" \;
              fi
            done
          done
        }

        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")
        for ((c = 0; c < NUM_COMPONENTS; c++)) ; do
            COMPONENT=$(jq -c --arg i "$c" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
            compress_components "$COMPONENT" 2> "$STDERR_FILE"
        done

    - name: push-artifacts
      image: quay.io/konflux-ci/release-service-utils:de01eb742f1fabeaefd1aabce1b24061b3fe72e1
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi
          cpu: 250m
      volumeMounts:
        - name: shared-dir
          mountPath: /shared
        - name: exodus-gw-secret
          mountPath: /mnt/exodusGwSecret
        - name: pulp-secret
          mountPath: /mnt/pulpSecret
        - name: udcache-secret
          mountPath: /mnt/udcacheSecret
        - name: cgw-secret
          mountPath: /mnt/cgwSecret
      env:
        - name: "SNAPSHOT_JSON"
          value: "$(params.snapshot_json)"
      script: |
        #!/usr/bin/env bash
        set -e

        EXODUS_CERT="$(cat /mnt/exodusGwSecret/cert)"
        EXODUS_KEY="$(cat /mnt/exodusGwSecret/key)"
        EXODUS_URL="$(cat /mnt/exodusGwSecret/url)"
        PULP_URL="$(cat /mnt/pulpSecret/pulp_url)"
        PULP_CERT="$(cat /mnt/pulpSecret/konflux-release-rhsm-pulp.crt)"
        PULP_KEY="$(cat /mnt/pulpSecret/konflux-release-rhsm-pulp.key)"
        UDC_URL="$(cat /mnt/udcacheSecret/url)"
        UDC_CERT="$(cat /mnt/udcacheSecret/cert)"
        UDC_KEY="$(cat /mnt/udcacheSecret/key)"
        CGW_USERNAME="$(cat /mnt/cgwSecret/username)"
        CGW_PASSWORD="$(cat /mnt/cgwSecret/token)"

        # export the variables used by the scripts in release-service-utils
        export CGW_USERNAME CGW_PASSWORD

        set -x

        STDERR_FILE=/tmp/stderr.txt

        # Check if the previous step finished successfully. If not, stop here.
        if [ "$(cat "$(results.result.path)")" != "Success" ]; then
          echo "Previous step failed. Exiting..."
          exit 0
        fi

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                # cleaning up the publishedFiles result to clean up space in the results buffer
                echo > "$(results.publishedFiles.path)"
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    # save output to the task result excluding the trace log
                    grep -v "^\+" "$STDERR_FILE" | tail -c 512 | tee -a "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        # Setup required variables
        export EXODUS_GW_CERT=/tmp/exodus.crt
        export EXODUS_GW_KEY=/tmp/exodus.key
        EXODUS_CONF_PATH=/tmp/exodus-rsync.conf
        export PULP_CERT_FILE=/tmp/pulp.crt
        export PULP_KEY_FILE=/tmp/pulp.key
        export UDCACHE_CERT=/tmp/udc.crt
        export UDCACHE_KEY=/tmp/udc.key
        EXODUS_GW_ENV=$(params.exodusGwEnv)
        export EXODUS_GW_ENV
        export EXODUS_GW_URL="$EXODUS_URL"
        export EXODUS_PULP_HOOK_ENABLED=True
        export EXODUS_GW_TIMEOUT=7200

        set +x
        echo "$EXODUS_CERT" > "$EXODUS_GW_CERT"
        echo "$EXODUS_KEY" > "$EXODUS_GW_KEY"
        echo "$PULP_CERT" > "$PULP_CERT_FILE"
        echo "$PULP_KEY" > "$PULP_KEY_FILE"
        echo "$UDC_CERT" > "$UDCACHE_CERT"
        echo "$UDC_KEY" > "$UDCACHE_KEY"
        set -x

        DISK_IMAGE_DIR="/shared/artifacts/compressed"
        export DISK_IMAGE_DIR
        RELATIVE_PATHS=""

        # save the results
        find "${DISK_IMAGE_DIR}" -type f -exec basename {} \; | tail -c 512 | tee "$(results.publishedFiles.path)"

        push_to_pulp() {
          # use the 1st component's version for STAGED_JSON
          version=$(jq -cr '.components[0].staged.version // ""' <<< "$SNAPSHOT_JSON")
          # Check if staged.destination exists in any component
          has_staged_destination=$(jq 'any(.components[]?.staged?.destination; . != null)' <<< "$SNAPSHOT_JSON")
          if [[ -z "$version" || "$has_staged_destination" != "true" ]]; then
            echo "Error: Pulp push requires both staged.version and components[].staged.destination to be set" >&2
            exit 1
          fi

          echo "Pushing to customer portal with pulp"
          staged_json='{"header":{"version": "0.2"},"payload":{"files":[]}}'
          # Add the files to the payload
          # shell check wants us to find ./* but that adds `./` to the paths which breaks the script
          # shellcheck disable=SC2035
          while IFS= read -r -d '' file ; do
              staged_json=$(jq --arg filename "$(basename "$file")" --arg path "$file" \
                --arg version "$version" \
                '.payload.files[.payload.files | length] =
                {"filename": $filename, "relative_path": $path, "version": $version}' <<< "$staged_json")
          done < <(find * -type f -print0)
          echo "$staged_json" | yq -P -I 4 > staged.yaml

          pulp_push_wrapper --debug --source "${DISK_IMAGE_DIR}" --pulp-url "$PULP_URL" \
            --pulp-cert $PULP_CERT_FILE --pulp-key $PULP_KEY_FILE --udcache-url "$UDC_URL"
          RELATIVE_PATHS=$(jq -erc '.payload.files[].relative_path' <<< "$staged_json")

          # Clean up file to avoid uploading it in exodus-rsync as an artifact.
          rm -f staged.yaml
         }

        create_exodus_conf() {
          echo "Creating Exodus configuration file....."
          set +x
          cat >"$EXODUS_CONF_PATH" <<EOF
        gwcert:   $EXODUS_GW_CERT
        gwkey:    $EXODUS_GW_KEY
        gwurl:    $EXODUS_GW_URL
        gwenv:    $EXODUS_GW_ENV

        logger: file:/proc/1/fd/1
        loglevel: info

        environments:
          - prefix: exodus
        EOF
          set -x
        }

        push_to_cdn () {
            echo "Pushing to CDN with exodus-rsync"
            create_exodus_conf
            prefix="exodus:/content/origin/files/sha256"
            files_output="{}"
            # shell check wants us to find ./* but that adds `./` to the paths which breaks the script
            # shellcheck disable=SC2035
            while IFS= read -r -d '' file; do
              set +x
              file_name=$(basename "$file")
              checksum=$(sha256sum "$file" | awk '{print $1}')
              destination_path="$prefix/${checksum:0:2}/$checksum/$file_name"
              files_output=$(jq --arg key "$file" \
                --arg value "$destination_path" '.[$key]=$value' <<< "$files_output")
              set -x

              # We're using exodus-rsync as a drop-in replacement for rsync, by overriding the rsync binary.
              rsync --exodus-conf "$EXODUS_CONF_PATH" "$file" "$destination_path"
            done < <(find * -type f -print0)
            RELATIVE_PATHS=$(jq -erc 'keys[]' <<< "$files_output")
        }

        publish_to_cgw() {
          NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")
          i=0
          for path in $RELATIVE_PATHS; do
            [[ $i -ge "$NUM_COMPONENTS" ]] && break  # stop once we've processed all components
            component_destination="${DISK_IMAGE_DIR}/$(dirname "$path")"

            SNAPSHOT_JSON=$(
              jq --argjson i "$i" --arg dir "$component_destination" '
                .components[$i] |=
                  if .contentGateway? then
                    .contentGateway.contentDir = $dir
                  else
                    . # components without contentGateway will not be published.
                  end
              ' <<<"$SNAPSHOT_JSON"
            )
            ((++i))
          done

          ## Process Files for Developer Portal / CGW
          ## Validation of fields done inside CGW wrapper.
          publish_to_cgw_wrapper \
            --cgw_host "$(params.cgwHostname)" \
            --data_json "$SNAPSHOT_JSON"
        }

        # Change to the subdir with the images
        cd "${DISK_IMAGE_DIR}"

        # Check if any component has staged defined further validation of fields done inside the function.
        CUSTOMER_PORTAL_PUSH=$(jq 'any(.components[]?.staged?; length > 0)' <<< "$SNAPSHOT_JSON")
        # Check if any component has contentGateway defined validaion of field done inside CGW wrapper.
        CGW_PUSH=$(jq 'any(.components[]?.contentGateway?; length > 0)' <<< "$SNAPSHOT_JSON")
        if [[ "$CUSTOMER_PORTAL_PUSH" == "true" && "$CGW_PUSH" == "true" ]]; then
          push_to_pulp 2> "$STDERR_FILE"
          publish_to_cgw 2> >(tee "$STDERR_FILE" >&2)
        elif [[ "$CUSTOMER_PORTAL_PUSH" == "true" ]]; then
          push_to_pulp 2> "$STDERR_FILE"
        elif [[ "$CGW_PUSH" == "true" ]]; then
          push_to_cdn > >(tee "$STDERR_FILE") 2>&1
          publish_to_cgw 2> >(tee "$STDERR_FILE" >&2)
        fi
